{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-31T16:10:52.796735Z",
     "start_time": "2025-01-31T16:10:49.953452Z"
    }
   },
   "source": [
    "from massspecgym.data.datasets import MSnDataset\n",
    "from massspecgym.featurize import SpectrumFeaturizer\n",
    "from massspecgym.data import RetrievalDataset, MassSpecDataModule\n",
    "import os\n",
    "from phantoms.utils.custom_tokenizers import ByteBPETokenizerWithSpecialTokens\n",
    "import selfies as sf"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:10:52.801974Z",
     "start_time": "2025-01-31T16:10:52.800010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectra_mgf = \"/Users/macbook/CODE/Majer:MassSpecGym/data/MSn/20241211_msn_library_pos_all_lib_MSn.mgf\"\n",
    "split_file = \"/Users/macbook/CODE/Majer:MassSpecGym/data/MSn/20241211_split.tsv\""
   ],
   "id": "704481446b0e690",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:10:52.889576Z",
     "start_time": "2025-01-31T16:10:52.887486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    'features': ['binned_peaks'],\n",
    "    'feature_attributes': {\n",
    "        'binned_peaks': {\n",
    "            'max_mz': 1000,\n",
    "            'bin_width': 0.25,\n",
    "            'to_rel_intensities': True,\n",
    "        },\n",
    "    },\n",
    "}"
   ],
   "id": "832af68b36b47d97",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:10:52.895449Z",
     "start_time": "2025-01-31T16:10:52.893727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "featurizer = SpectrumFeaturizer(config, mode='torch')\n",
    "batch_size = 12"
   ],
   "id": "253cea2b124ce5f4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:14:41.198737Z",
     "start_time": "2025-01-31T16:10:52.899951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "msn_dataset = MSnDataset(\n",
    "    pth=spectra_mgf,\n",
    "    featurizer=featurizer,\n",
    "    mol_transform=None,\n",
    "    max_allowed_deviation=0.005\n",
    ")"
   ],
   "id": "14a927571218b88a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:14:41.205568Z",
     "start_time": "2025-01-31T16:14:41.203756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_module_msn = MassSpecDataModule(\n",
    "    dataset=msn_dataset,\n",
    "    batch_size=batch_size,\n",
    "    split_pth=split_file,\n",
    "    num_workers=0,\n",
    ")"
   ],
   "id": "c5b2ed027e3b25a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:14:41.211344Z",
     "start_time": "2025-01-31T16:14:41.210034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "smiles_list = msn_dataset.smiles "
   ],
   "id": "c5d71507158d96ff",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train on MSn SMILES",
   "id": "e9fa0ffaae1bd140"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:14:41.227957Z",
     "start_time": "2025-01-31T16:14:41.225661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SMILES_TOKENIZER_SAVE_PATH = \"/Users/macbook/CODE/Majer:MassSpecGym/data/tokenizers/smiles_tokenizer.json\"\n",
    "SELFIES_TOKENIZER_SAVE_PATH = \"/Users/macbook/CODE/Majer:MassSpecGym/data/tokenizers/selfies_tokenizer.json\"\n",
    "\n",
    "os.makedirs(os.path.dirname(SMILES_TOKENIZER_SAVE_PATH), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(SELFIES_TOKENIZER_SAVE_PATH), exist_ok=True)"
   ],
   "id": "19a76bdc7ec0ce91",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:14:43.549202Z",
     "start_time": "2025-01-31T16:14:41.232772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve SMILES from the dataset\n",
    "smiles_list = msn_dataset.smiles \n",
    "selfies_list = [sf.encoder(smi, strict=False) for smi in smiles_list]"
   ],
   "id": "94a1264718a6cfbe",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:14:43.642770Z",
     "start_time": "2025-01-31T16:14:43.554254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nInitializing and Training SMILES Tokenizer...\")\n",
    "smiles_tokenizer = ByteBPETokenizerWithSpecialTokens(max_len=200)\n",
    "\n",
    "smiles_tokenizer.train(\n",
    "    texts=smiles_list,\n",
    "    vocab_size=1000,\n",
    "    min_frequency=2,\n",
    "    save_path=SMILES_TOKENIZER_SAVE_PATH,\n",
    "    show_progress=True\n",
    ")"
   ],
   "id": "c3596114c36cb224",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing and Training SMILES Tokenizer...\n",
      "Initialized a new Byte-Level BPE Tokenizer.\n",
      "Starting training on 16476 texts...\n",
      "\n",
      "\n",
      "\n",
      "Training complete.\n",
      "Tokenizer saved to /Users/macbook/CODE/Majer:MassSpecGym/data/tokenizers/smiles_tokenizer.json.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T16:14:43.812182Z",
     "start_time": "2025-01-31T16:14:43.647863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"\\nInitializing and Training SELFIES Tokenizer...\")\n",
    "selfies_tokenizer = ByteBPETokenizerWithSpecialTokens(max_len=200)\n",
    "\n",
    "selfies_tokenizer.train(\n",
    "    texts=selfies_list,\n",
    "    vocab_size=1000,       \n",
    "    min_frequency=1,   \n",
    "    save_path=SELFIES_TOKENIZER_SAVE_PATH,\n",
    "    show_progress=True\n",
    ")"
   ],
   "id": "faf5a1da9577c366",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing and Training SELFIES Tokenizer...\n",
      "Initialized a new Byte-Level BPE Tokenizer.\n",
      "Starting training on 16476 texts...\n",
      "\n",
      "\n",
      "\n",
      "Training complete.\n",
      "Tokenizer saved to /Users/macbook/CODE/Majer:MassSpecGym/data/tokenizers/selfies_tokenizer.json.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T08:22:42.627786Z",
     "start_time": "2025-02-01T08:22:42.621010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 6: Verify SMILES Tokenizer\n",
    "print(\"\\nVerifying SMILES Tokenizer...\")\n",
    "sample_smiles = \"COC1=C(C=C(C=C1)CCC(=O)C2=C#(C=C(C=C2OC)OC)O)OC\" \n",
    "smiles_tokenizer = ByteBPETokenizerWithSpecialTokens(tokenizer_path=SMILES_TOKENIZER_SAVE_PATH)\n",
    "encoded_smiles = smiles_tokenizer.encode(sample_smiles)\n",
    "print(f\"Encoded SMILES: {encoded_smiles}\")\n",
    "\n",
    "decoded_smiles = smiles_tokenizer.decode(encoded_smiles)\n",
    "print(f\"Decoded SMILES: {decoded_smiles}\")\n",
    "\n",
    "# Step 7: Verify SELFIES Tokenizer\n",
    "selfies_tokenizer = ByteBPETokenizerWithSpecialTokens(tokenizer_path=SELFIES_TOKENIZER_SAVE_PATH)\n",
    "print(\"\\nVerifying SELFIES Tokenizer...\")\n",
    "encoded_selfies = selfies_tokenizer.encode(sample_smiles)  \n",
    "print(f\"Encoded SELFIES: {encoded_selfies}\")\n",
    "decoded_selfies = selfies_tokenizer.decode(encoded_selfies)\n",
    "print(f\"Decoded SMILES: {decoded_selfies}\")"
   ],
   "id": "570061558c5b1ace",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying SMILES Tokenizer...\n",
      "Loaded tokenizer from /Users/macbook/CODE/Majer:MassSpecGym/data/tokenizers/smiles_tokenizer.json.\n",
      "Encoded SMILES: [1, 283, 20, 32, 38, 11, 38, 32, 38, 11, 38, 32, 38, 20, 12, 269, 261, 50, 12, 38, 21, 32, 38, 6, 11, 38, 32, 38, 11, 38, 32, 38, 21, 265, 12, 265, 12, 50, 12, 265, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded SMILES:  COC1=C(C=C(C=C1)CCC(=O)C2=C#(C=C(C=C2OC)OC)O)OC\n",
      "Loaded tokenizer from /Users/macbook/CODE/Majer:MassSpecGym/data/tokenizers/selfies_tokenizer.json.\n",
      "\n",
      "Verifying SELFIES Tokenizer...\n",
      "Encoded SELFIES: [1, 224, 38, 50, 38, 20, 32, 38, 11, 38, 32, 38, 11, 38, 32, 38, 20, 12, 38, 38, 38, 11, 32, 50, 12, 38, 21, 32, 38, 6, 11, 38, 32, 38, 11, 38, 32, 38, 21, 50, 38, 12, 50, 38, 12, 50, 12, 50, 38, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded SMILES:  COC1=C(C=C(C=C1)CCC(=O)C2=C#(C=C(C=C2OC)OC)O)OC\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run from yml",
   "id": "e5e027c1922ff825"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T08:06:55.670324Z",
     "start_time": "2025-02-21T08:06:55.102479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "from datetime import datetime\n",
    "import os\n",
    "from phantoms.utils.custom_tokenizers.parser import train_tokenizer"
   ],
   "id": "2c50de70e08ba37d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T08:07:15.200590Z",
     "start_time": "2025-02-21T08:07:15.196717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_path = \"/Users/macbook/CODE/PhantoMS/phantoms/utils/custom_tokenizers/configs/bpe_local.yml\"\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f) \n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "experiment_folder = os.path.join(\"/Users/macbook/CODE/PhantoMS/experiments_run\",\n",
    "                                 f\"{timestamp}_{config['experiment_base_name']}\")\n",
    "\n",
    "tokenizer_path = os.path.join(experiment_folder, \"smiles_tokenizer.json\")\n",
    "config['model'][\"smiles_tokenizer_save_path\"] = tokenizer_path"
   ],
   "id": "47297df8c5ced893",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T08:07:32.294356Z",
     "start_time": "2025-02-21T08:07:17.696555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "train_tokenizer(config, experiment_folder, config_path)"
   ],
   "id": "a008b520e886b59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-21_09-07-15_tokenizer_large/configs/bpe_local.yml\n",
      "Training tokenizer from TSV file(s).\n",
      "Found 633087 SMILES in /Users/macbook/CODE/Majer:MassSpecGym/data/MSn/20241211_1M_murcko_train_smiles.tsv.\n",
      "Found 1883319 SMILES in /Users/macbook/CODE/Majer:MassSpecGym/data/MSn/20241211_4M_murcko_train_smiles.tsv.\n",
      "Total SMILES for training: 2516406\n",
      "Initialized a new Byte-Level BPE Tokenizer.\n",
      "Starting training on 2516406 texts...\n",
      "\n",
      "\n",
      "\n",
      "Training complete.\n",
      "Tokenizer saved to /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-21_09-07-15_tokenizer_large/smiles_tokenizer.json.\n",
      "Tokenizer training complete and saved to /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-21_09-07-15_tokenizer_large/smiles_tokenizer.json\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T09:00:06.790828Z",
     "start_time": "2025-01-31T09:00:06.789202Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "213a9ddb6c2bf2c8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
