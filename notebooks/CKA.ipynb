{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Below is one practical approach to (1) capture intermediate embeddings from your GNN (so you can compare them via PCA/t-SNE/CKA), and (2) systematically compare models trained at different MSn depths (e.g., cut_tree_at_level=2 vs. cut_tree_at_level=5). This does not rely on PyG’s “Explainability” module, but rather on extracting and saving hidden representations, then applying any off-the-shelf representation-similarity method (such as CKA).\n",
    "\n",
    "1) Modify Your Model to Output Intermediate Embeddings\n",
    "\n",
    "Right now, your GNNRetrievalModel only returns the final fingerprint. We can add a separate method (e.g., forward_with_embeds) that also returns hidden embeddings at various points:\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from massspecgym.models.base import Stage, MassSpecGymModel\n",
    "from massspecgym.models.retrieval.base import RetrievalMassSpecGymModel\n",
    "\n",
    "class GNNRetrievalModel(RetrievalMassSpecGymModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels: int = 128,\n",
    "        out_channels: int = 4096,  # Fingerprint size\n",
    "        node_feature_dim: int = 1039,  # Adjust based on your 'spec.x' feature size\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"GNN-based retrieval model for MSn spectral trees.\"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # GCN Layers\n",
    "        self.conv1 = GCNConv(in_channels=node_feature_dim, out_channels=hidden_channels)\n",
    "        self.conv2 = GCNConv(in_channels=hidden_channels, out_channels=hidden_channels)\n",
    "        \n",
    "        # Fully Connected Layers for Fingerprint Prediction\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, out_channels),\n",
    "            nn.Sigmoid()  # Fingerprint bits between 0 and 1\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Original forward pass to predict molecular fingerprint.\n",
    "        \"\"\"\n",
    "        # -> Just calls a helper that returns final output\n",
    "        x_out, _, _, _ = self.forward_with_embeds(data)\n",
    "        return x_out\n",
    "    \n",
    "    def forward_with_embeds(self, data):\n",
    "        \"\"\"\n",
    "        Extended forward pass that also returns intermediate embeddings:\n",
    "\n",
    "        Returns:\n",
    "          x_out: Final [batch_size, fp_size] fingerprint.\n",
    "          x1:    Node embeddings after conv1 + ReLU   (shape: [num_nodes, hidden_channels]).\n",
    "          x2:    Node embeddings after conv2 + ReLU   (shape: [num_nodes, hidden_channels]).\n",
    "          x_pool: Graph-level embedding after global_mean_pool (shape: [batch_size, hidden_channels]).\n",
    "        \"\"\"\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # First GCN\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x1 = F.relu(x)  # Node embeddings after conv1\n",
    "\n",
    "        # Second GCN\n",
    "        x = self.conv2(x1, edge_index)\n",
    "        x2 = F.relu(x)  # Node embeddings after conv2\n",
    "        \n",
    "        # Pool to graph-level\n",
    "        x_pool = global_mean_pool(x2, batch)  # [batch_size, hidden_channels]\n",
    "        \n",
    "        # Final fingerprint\n",
    "        x_out = self.fc(x_pool)  # [batch_size, fp_size]\n",
    "        \n",
    "        return x_out, x1, x2, x_pool\n",
    "    \n",
    "    def step(self, batch: dict, stage: Stage) -> dict:\n",
    "        \"\"\"\n",
    "        Training/Validation/Test step.\n",
    "        \"\"\"\n",
    "        data = batch['spec']          # PyG DataBatch\n",
    "        fp_true = batch['mol']        # [batch_size, fp_size]\n",
    "        cands = batch['candidates']   # [total_candidates, fp_size]\n",
    "        batch_ptr = batch['batch_ptr']  # shape: [batch_size]\n",
    "\n",
    "        fp_pred = self.forward(data)  # [batch_size, fp_size]\n",
    "        \n",
    "        # MSE loss\n",
    "        loss = F.mse_loss(fp_pred, fp_true)\n",
    "        \n",
    "        # Evaluate retrieval scores\n",
    "        fp_pred_repeated = fp_pred.repeat_interleave(batch_ptr, dim=0)  # [total_candidates, fp_size]\n",
    "        scores = F.cosine_similarity(fp_pred_repeated, cands)           # [total_candidates]\n",
    "        \n",
    "        return {'loss': loss, 'scores': scores}\n",
    "\n",
    "\t•\tforward_with_embeds(...) is the key addition, returning:\n",
    "\t•\tx_out: the final fingerprint (same shape as your original forward).\n",
    "\t•\tx1: node embeddings after the first GCN+ReLU.\n",
    "\t•\tx2: node embeddings after the second GCN+ReLU.\n",
    "\t•\tx_pool: the pooled graph embedding (before the final MLP that produces the fingerprint).\n",
    "\n",
    "2) A Helper Function to Collect Embeddings Over a Dataloader\n",
    "\n",
    "We want to run our model on a set of examples (like the test set) and stack all embeddings. For instance, if we only care about the final graph-level embeddings (x_pool or x_out), we can store them for each example. If you also want node-level embeddings (x1, x2), note that each batch can have a variable number of nodes per graph—so you’d handle that carefully.\n",
    "\n",
    "Below is an example focusing on the graph-level embeddings (x_pool and x_out) because that’s simpler to compare across examples. If you also need node-level embeddings, you’d store them in a list-of-lists structure or carefully track the batch index.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def collect_graph_embeddings(model, data_loader, device='cpu'):\n",
    "    \"\"\"\n",
    "    Runs `model.forward_with_embeds(...)` on each batch in `data_loader`,\n",
    "    collecting graph-level embeddings (both x_pool and final x_out).\n",
    "    \n",
    "    Returns:\n",
    "       - all_pool: np.array of shape [num_graphs, hidden_channels]\n",
    "       - all_out:  np.array of shape [num_graphs, fp_size]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    all_pool = []\n",
    "    all_out = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_dict in data_loader:\n",
    "            data = batch_dict['spec'].to(device)\n",
    "            \n",
    "            x_out, x1, x2, x_pool = model.forward_with_embeds(data)\n",
    "            # x_out:  [batch_size, fp_size]\n",
    "            # x_pool: [batch_size, hidden_channels]\n",
    "            \n",
    "            # Convert to CPU numpy\n",
    "            all_pool.append(x_pool.cpu().numpy())\n",
    "            all_out.append(x_out.cpu().numpy())\n",
    "    \n",
    "    all_pool = np.concatenate(all_pool, axis=0)  # shape = [num_samples, hidden_channels]\n",
    "    all_out = np.concatenate(all_out, axis=0)    # shape = [num_samples, fp_size]\n",
    "\n",
    "    return all_pool, all_out\n",
    "\n",
    "3) Train (or Load) Multiple Models at Different MSn Depths\n",
    "\n",
    "You mentioned you have code like:\n",
    "\n",
    "# Example: cut_tree_at_level=2\n",
    "dataset_msn_l2 = MSnRetrievalDataset(\n",
    "    pth=file_mgf,\n",
    "    candidates_pth=file_json,\n",
    "    featurizer=featurizer,\n",
    "    mol_transform=MolFingerprinter(fp_size=fp_size),\n",
    "    max_allowed_deviation=0.005,\n",
    "    cut_tree_at_level=2\n",
    ")\n",
    "data_module_msn_l2 = MassSpecDataModule(\n",
    "    dataset=dataset_msn_l2,\n",
    "    batch_size=50,\n",
    "    split_pth=split_file,\n",
    "    num_workers=0,\n",
    ")\n",
    "model_l2 = GNNRetrievalModel(...)  # same architecture\n",
    "\n",
    "# Train or load checkpoint\n",
    "trainer.fit(model_l2, datamodule=data_module_msn_l2)\n",
    "trainer.save_checkpoint(\"gnn_l2.ckpt\")\n",
    "\n",
    "Repeat for cut_tree_at_level=3, 4, or 5, storing each as gnn_l3.ckpt, etc.\n",
    "\n",
    "4) Collect Embeddings on a Common Test Set\n",
    "\n",
    "To compare embeddings, you ideally want to feed the same input molecules to each model. For best apples-to-apples comparison, do one of the following:\n",
    "\t1.\tUse the same test split file for each dataset, so each “batch” has the same molecules (though the deeper MSn trees have more nodes).\n",
    "\t2.\tOr create a common test list of molecule IDs and build the PyG Data objects.\n",
    "\n",
    "Below is an illustration using each model’s own test loader. If your splits are indeed identical, the same batch order will correspond to the same molecules. If not, you’ll need a consistent alignment step.\n",
    "\n",
    "# Suppose we have test loaders for each dataset:\n",
    "data_module_msn_l2.setup(stage=\"test\")\n",
    "test_loader_l2 = data_module_msn_l2.test_dataloader()\n",
    "\n",
    "data_module_msn_l3.setup(stage=\"test\")\n",
    "test_loader_l3 = data_module_msn_l3.test_dataloader()\n",
    "\n",
    "# Load the trained models from checkpoint\n",
    "model_l2 = GNNRetrievalModel(...)\n",
    "model_l2.load_state_dict(torch.load(\"gnn_l2.ckpt\")[\"state_dict\"])\n",
    "\n",
    "model_l3 = GNNRetrievalModel(...)\n",
    "model_l3.load_state_dict(torch.load(\"gnn_l3.ckpt\")[\"state_dict\"])\n",
    "\n",
    "# Collect embeddings\n",
    "pool_l2, out_l2 = collect_graph_embeddings(model_l2, test_loader_l2, device='cpu')\n",
    "pool_l3, out_l3 = collect_graph_embeddings(model_l3, test_loader_l3, device='cpu')\n",
    "\n",
    "\t•\tpool_l2: shape = ￼ with the graph embeddings from the second GCN.\n",
    "\t•\tout_l2: shape = ￼ with final fingerprints.\n",
    "\n",
    "Same for L3, etc.\n",
    "\n",
    "If your test sets truly contain the same molecules in the same order, then pool_l2[i] corresponds to the same molecule as pool_l3[i]. If not, you have to realign them by an identifier (like batch_dict['identifier']).\n",
    "\n",
    "5) Do PCA, t-SNE, or CKA on the Resulting Embeddings\n",
    "\n",
    "With these numpy arrays, you can proceed to compare the embeddings. For example, CKA using your code snippet:\n",
    "\n",
    "from cka import linear_CKA, kernel_CKA  # or wherever your CKA code is\n",
    "\n",
    "print(\"Compare final graph embeddings from L2 vs L3 (out-layer) with linear CKA:\")\n",
    "cka_out = linear_CKA(out_l2, out_l3)\n",
    "print(\"CKA on final fingerprint outputs:\", cka_out)\n",
    "\n",
    "print(\"Compare the pooled hidden state from L2 vs L3 with RBF kernel CKA:\")\n",
    "cka_pool = kernel_CKA(pool_l2, pool_l3)\n",
    "print(\"CKA on pooled hidden layer:\", cka_pool)\n",
    "\n",
    "Or if you want to do t-SNE:\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne_embeddings = TSNE(n_components=2, perplexity=30).fit_transform(pool_l2)\n",
    "plt.scatter(tsne_embeddings[:,0], tsne_embeddings[:,1], s=5)\n",
    "plt.title(\"TSNE of GNN-l2 Pooled Embeddings\")\n",
    "plt.show()\n",
    "\n",
    "You could do the same for pool_l3, then compare visually.\n",
    "\n",
    "6) Extending to More Depths or More Models\n",
    "\n",
    "You can do exactly the same steps for a list of depths: [2, 3, 4, 5]. You’ll end up with 4 arrays of embeddings. Then run pairwise CKA or do multi-dimensional scaling, etc. Some approaches:\n",
    "\t•\tPairwise: CKA(pool_l2, pool_l3), CKA(pool_l2, pool_l4), CKA(pool_l3, pool_l5), etc.\n",
    "\t•\tMatrix: Build a matrix of shape (4×4), where entry ￼ = CKA(pool_i, pool_j), then do a heatmap.\n",
    "\n",
    "Putting It All Together\n",
    "\t1.\tAdd a forward_with_embeds(...) method returning intermediate embeddings.\n",
    "\t2.\tTrain the same GNN architecture at different MSn tree cut depths.\n",
    "\t3.\tCollect embeddings on the same test set.\n",
    "\t4.\tCompare these embeddings with PCA, t-SNE, or CKA.\n",
    "\n",
    "This way, you’ll see numerically and visually how the learned representations differ (or stay similar) when you add deeper MSn levels—without relying on the internal PyG explainers. This is particularly straightforward for tasks like retrieval, where you care about final or near-final graph embeddings."
   ],
   "id": "4e5cbc40c86d5df0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
