{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-14T16:24:25.208077Z",
     "start_time": "2025-01-14T16:24:24.871385Z"
    }
   },
   "source": [
    "import pytorch_lightning as pl\n",
    "from phantoms.models.retrieval.gnn_retrieval_model import GNNRetrievalModel\n",
    "from massspecgym.data import RetrievalDataset, MassSpecDataModule\n",
    "from massspecgym.data.transforms import MolFingerprinter\n",
    "from massspecgym.featurize import SpectrumFeaturizer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from massspecgym.data.datasets import MSnRetrievalDataset\n",
    "import yaml"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:24:31.062047Z",
     "start_time": "2025-01-14T16:24:31.052851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Optional: Set random seed for reproducibility\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Load configuration\n",
    "config_path = '/Users/macbook/CODE/PhantoMS/phantoms/models/retrieval/configs/config_retrieval.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ],
   "id": "e1f2b97dc7ac47a8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:24:43.067492Z",
     "start_time": "2025-01-14T16:24:43.065402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Featurizer\n",
    "featurizer = SpectrumFeaturizer(config['featurizer'], mode='torch')"
   ],
   "id": "a00af2fc4b3ae388",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:28:10.730359Z",
     "start_time": "2025-01-14T16:24:50.504121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Dataset\n",
    "dataset_msn = MSnRetrievalDataset(\n",
    "    pth=config['data']['file_mgf'],\n",
    "    candidates_pth=config['data']['file_json'],\n",
    "    featurizer=featurizer,\n",
    "    mol_transform=MolFingerprinter(fp_size=config['model']['fp_size']),\n",
    "    max_allowed_deviation=config['data']['max_allowed_deviation']\n",
    ")"
   ],
   "id": "28c7bff0208d1e35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No candidates for 710 smiles. Skipping.\n",
      "Total valid indices: 15674\n",
      "Dataset length: 15674\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:37:59.148630Z",
     "start_time": "2025-01-14T16:37:59.145106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize DataModule\n",
    "data_module_msn = MassSpecDataModule(\n",
    "    dataset=dataset_msn,\n",
    "    batch_size=config['data']['batch_size'],\n",
    "    split_pth=config['data']['split_file'],\n",
    "    num_workers=config['data']['num_workers']\n",
    ")"
   ],
   "id": "edd8bac4e22252b4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:38:54.482554Z",
     "start_time": "2025-01-14T16:38:54.473440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Model\n",
    "model = GNNRetrievalModel(\n",
    "    hidden_channels=config['model']['hidden_channels'],\n",
    "    out_channels=config['model']['fp_size'],\n",
    "    node_feature_dim=config['model']['node_feature_dim'],\n",
    ")"
   ],
   "id": "a1a595a4c049a7fa",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:38:54.881558Z",
     "start_time": "2025-01-14T16:38:54.879620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Logger\n",
    "logger = TensorBoardLogger(save_dir=config['logs']['dir'], name=config['logs']['name'])\n"
   ],
   "id": "1989f94b6baeb0cf",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:38:55.368113Z",
     "start_time": "2025-01-14T16:38:55.350620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=config['trainer']['accelerator'],\n",
    "    devices=config['trainer']['devices'],\n",
    "    max_epochs=config['trainer']['max_epochs'],\n",
    "    logger=logger,\n",
    "    log_every_n_steps=config['trainer']['log_every_n_steps'],\n",
    "    limit_train_batches=config['trainer']['limit_train_batches'],\n",
    "    limit_val_batches=config['trainer']['limit_val_batches'],\n",
    "    limit_test_batches=config['trainer']['limit_test_batches'],\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            monitor=config['trainer']['checkpoint_monitor'],\n",
    "            save_top_k=config['trainer']['save_top_k'],\n",
    "            mode=config['trainer']['checkpoint_mode'],\n",
    "            dirpath=config['trainer']['checkpoint_dir'],\n",
    "            filename='gnn_retrieval-{epoch:02d}-{val_loss:.2f}'\n",
    "        ),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "    ]\n",
    ")"
   ],
   "id": "bdf5aaea80c08887",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:43:16.242786Z",
     "start_time": "2025-01-14T16:38:55.997378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "trainer.fit(model, datamodule=data_module_msn)"
   ],
   "id": "e505cf9fe6191c74",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type          | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | gcn1    | GCNLayer      | 133 K  | train\n",
      "1 | gcn2    | GCNLayer      | 16.5 K | train\n",
      "2 | head    | RetrievalHead | 544 K  | train\n",
      "3 | loss_fn | MSELoss       | 0      | train\n",
      "--------------------------------------------------\n",
      "694 K     Trainable params\n",
      "0         Non-trainable params\n",
      "694 K     Total params\n",
      "2.778     Total estimated model params size (MB)\n",
      "16        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Train dataset size: 11883\n",
      "Val dataset size: 1899\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in collate_fn\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  6.79it/s]in collate_fn\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] in collate_fn\n",
      "Epoch 0:  50%|█████     | 1/2 [00:06<00:06,  0.16it/s, v_num=2]in collate_fn\n",
      "Epoch 0: 100%|██████████| 2/2 [00:15<00:00,  0.13it/s, v_num=2, train_loss=0.367]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 12.83it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:08<00:00,  0.25it/s]\u001B[A\n",
      "Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, v_num=2, train_loss=0.354, val_loss=0.360]        in collate_fn\n",
      "Epoch 1:  50%|█████     | 1/2 [00:06<00:06,  0.17it/s, v_num=2, train_loss=0.354, val_loss=0.360]in collate_fn\n",
      "Epoch 1: 100%|██████████| 2/2 [00:15<00:00,  0.13it/s, v_num=2, train_loss=0.350, val_loss=0.360]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 12.74it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:08<00:00,  0.25it/s]\u001B[A\n",
      "Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, v_num=2, train_loss=0.343, val_loss=0.348]        in collate_fn\n",
      "Epoch 2:  50%|█████     | 1/2 [00:05<00:05,  0.17it/s, v_num=2, train_loss=0.343, val_loss=0.348]in collate_fn\n",
      "Epoch 2: 100%|██████████| 2/2 [00:15<00:00,  0.13it/s, v_num=2, train_loss=0.340, val_loss=0.348]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 12.73it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:08<00:00,  0.25it/s]\u001B[A\n",
      "Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, v_num=2, train_loss=0.332, val_loss=0.336]        in collate_fn\n",
      "Epoch 3:  50%|█████     | 1/2 [00:06<00:06,  0.16it/s, v_num=2, train_loss=0.332, val_loss=0.336]in collate_fn\n",
      "Epoch 3: 100%|██████████| 2/2 [00:14<00:00,  0.14it/s, v_num=2, train_loss=0.328, val_loss=0.336]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 12.74it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:08<00:00,  0.25it/s]\u001B[A\n",
      "Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, v_num=2, train_loss=0.323, val_loss=0.324]        in collate_fn\n",
      "Epoch 4:  50%|█████     | 1/2 [00:06<00:06,  0.16it/s, v_num=2, train_loss=0.323, val_loss=0.324]in collate_fn\n",
      "Epoch 4: 100%|██████████| 2/2 [00:17<00:00,  0.11it/s, v_num=2, train_loss=0.317, val_loss=0.324]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 12.79it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:08<00:00,  0.24it/s]\u001B[A\n",
      "Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, v_num=2, train_loss=0.310, val_loss=0.312]        in collate_fn\n",
      "Epoch 5:  50%|█████     | 1/2 [00:05<00:05,  0.17it/s, v_num=2, train_loss=0.310, val_loss=0.312]in collate_fn\n",
      "Epoch 5: 100%|██████████| 2/2 [00:14<00:00,  0.14it/s, v_num=2, train_loss=0.302, val_loss=0.312]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 12.78it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:08<00:00,  0.25it/s]\u001B[A\n",
      "Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, v_num=2, train_loss=0.296, val_loss=0.301]        in collate_fn\n",
      "Epoch 6:  50%|█████     | 1/2 [00:05<00:05,  0.17it/s, v_num=2, train_loss=0.296, val_loss=0.301]in collate_fn\n",
      "Epoch 6: 100%|██████████| 2/2 [00:14<00:00,  0.13it/s, v_num=2, train_loss=0.293, val_loss=0.301]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 12.83it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:08<00:00,  0.25it/s]\u001B[A\n",
      "Epoch 6: 100%|██████████| 2/2 [00:36<00:00,  0.05it/s, v_num=2, train_loss=0.289, val_loss=0.290]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=7` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:36<00:00,  0.05it/s, v_num=2, train_loss=0.289, val_loss=0.290]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:43:41.709284Z",
     "start_time": "2025-01-14T16:43:16.251617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the model\n",
    "trainer.test(model, datamodule=data_module_msn)"
   ],
   "id": "5371eb8a7483e003",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 1892\n",
      "Testing: |          | 0/? [00:00<?, ?it/s]in collate_fn\n",
      "Testing DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 25.80it/s]in collate_fn\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:19<00:00,  0.10it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_hit_rate@1                0.0\n",
      "    test_hit_rate@20                0.0\n",
      "     test_hit_rate@5                0.0\n",
      "        test_loss           0.2808142602443695\n",
      "       test_mces@1          26.774999618530273\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.2808142602443695,\n",
       "  'test_hit_rate@1': 0.0,\n",
       "  'test_hit_rate@5': 0.0,\n",
       "  'test_hit_rate@20': 0.0,\n",
       "  'test_mces@1': 26.774999618530273}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5ac2c5809e4de0c8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
