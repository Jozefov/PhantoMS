{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-15T05:48:42.079599Z",
     "start_time": "2025-01-15T05:48:41.315951Z"
    }
   },
   "source": [
    "import pytorch_lightning as pl\n",
    "from phantoms.models.retrieval.gnn_retrieval_model import GNNRetrievalModel\n",
    "from massspecgym.data import RetrievalDataset, MassSpecDataModule\n",
    "from massspecgym.data.transforms import MolFingerprinter\n",
    "from massspecgym.featurize import SpectrumFeaturizer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from massspecgym.data.datasets import MSnRetrievalDataset\n",
    "import yaml\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T06:16:10.870556Z",
     "start_time": "2025-01-15T06:16:10.859017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Optional: Set random seed for reproducibility\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Load configuration\n",
    "config_path = '/Users/macbook/CODE/PhantoMS/phantoms/models/retrieval/configs/config_retrieval.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "experiment_name = config.get('experiment_name', 'default_experiment')"
   ],
   "id": "e1f2b97dc7ac47a8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:48:42.343404Z",
     "start_time": "2025-01-15T05:48:42.341328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Featurizer\n",
    "featurizer = SpectrumFeaturizer(config['featurizer'], mode='torch')"
   ],
   "id": "a00af2fc4b3ae388",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:52:40.542308Z",
     "start_time": "2025-01-15T05:48:44.688018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Dataset\n",
    "dataset_msn = MSnRetrievalDataset(\n",
    "    pth=config['data']['file_mgf'],\n",
    "    candidates_pth=config['data']['file_json'],\n",
    "    featurizer=featurizer,\n",
    "    mol_transform=MolFingerprinter(fp_size=config['model']['fp_size']),\n",
    "    max_allowed_deviation=config['data']['max_allowed_deviation']\n",
    ")"
   ],
   "id": "28c7bff0208d1e35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No candidates for 710 smiles. Skipping.\n",
      "Total valid indices: 15674\n",
      "Dataset length: 15674\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:52:40.566824Z",
     "start_time": "2025-01-15T05:52:40.562012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize DataModule\n",
    "data_module_msn = MassSpecDataModule(\n",
    "    dataset=dataset_msn,\n",
    "    batch_size=config['data']['batch_size'],\n",
    "    split_pth=config['data']['split_file'],\n",
    "    num_workers=config['data']['num_workers']\n",
    ")"
   ],
   "id": "edd8bac4e22252b4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:52:40.623247Z",
     "start_time": "2025-01-15T05:52:40.616609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Model\n",
    "model = GNNRetrievalModel(\n",
    "    hidden_channels=config['model']['hidden_channels'],\n",
    "    out_channels=config['model']['fp_size'],\n",
    "    node_feature_dim=config['model']['node_feature_dim'],\n",
    ")"
   ],
   "id": "a1a595a4c049a7fa",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T06:16:26.932508Z",
     "start_time": "2025-01-15T06:16:26.929204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Logger\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=config['logs']['dir'],\n",
    "    name=config['logs']['name'],\n",
    "    version=experiment_name  # Use experiment_name as the version\n",
    ")"
   ],
   "id": "1989f94b6baeb0cf",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T06:16:27.319322Z",
     "start_time": "2025-01-15T06:16:27.316996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wandb_logger = WandbLogger(\n",
    "    project=config['wandb']['project'],\n",
    "    entity=config['wandb']['entity'],\n",
    "    name=experiment_name,  # Name the run with experiment_name\n",
    "    log_model=\"all\"  # Log all models (optional)\n",
    ")"
   ],
   "id": "a812bb3f1459ff4c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T06:31:10.260031Z",
     "start_time": "2025-01-15T06:31:10.256610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define experiment-specific checkpoint directory\n",
    "checkpoint_dir = os.path.join(config['trainer']['checkpoint_dir'], experiment_name)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ],
   "id": "4de0be7fcfa892c8",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T06:31:10.532160Z",
     "start_time": "2025-01-15T06:31:10.500455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=config['trainer']['accelerator'],\n",
    "    devices=config['trainer']['devices'],\n",
    "    max_epochs=config['trainer']['max_epochs'],\n",
    "    logger=[logger, wandb_logger],\n",
    "    log_every_n_steps=config['trainer']['log_every_n_steps'],\n",
    "    limit_train_batches=config['trainer']['limit_train_batches'],\n",
    "    limit_val_batches=config['trainer']['limit_val_batches'],\n",
    "    limit_test_batches=config['trainer']['limit_test_batches'],\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            monitor=config['trainer']['checkpoint_monitor'],\n",
    "            save_top_k=config['trainer']['save_top_k'],\n",
    "            mode=config['trainer']['checkpoint_mode'],\n",
    "            dirpath=checkpoint_dir,\n",
    "            filename='gnn_retrieval-{epoch:02d}-{val_loss:.2f}'\n",
    "        ),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "    ]\n",
    ")"
   ],
   "id": "bdf5aaea80c08887",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T06:36:52.052253Z",
     "start_time": "2025-01-15T06:31:11.125479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "trainer.fit(model, datamodule=data_module_msn)"
   ],
   "id": "e505cf9fe6191c74",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/macbook/CODE/PhantoMS/notebooks/checkpoints/experiment_1 exists and is not empty.\n",
      "\n",
      "   | Name              | Type          | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0  | gcn1              | GCNLayer      | 133 K  | eval \n",
      "1  | gcn2              | GCNLayer      | 16.5 K | eval \n",
      "2  | head              | RetrievalHead | 544 K  | eval \n",
      "3  | loss_fn           | MSELoss       | 0      | eval \n",
      "4  | val_hit_rate@1    | MeanMetric    | 0      | train\n",
      "5  | val_hit_rate@5    | MeanMetric    | 0      | train\n",
      "6  | val_hit_rate@20   | MeanMetric    | 0      | train\n",
      "7  | val_mces@1        | MeanMetric    | 0      | train\n",
      "8  | train_hit_rate@1  | MeanMetric    | 0      | train\n",
      "9  | train_hit_rate@5  | MeanMetric    | 0      | train\n",
      "10 | train_hit_rate@20 | MeanMetric    | 0      | train\n",
      "11 | train_mces@1      | MeanMetric    | 0      | train\n",
      "12 | test_hit_rate@1   | MeanMetric    | 0      | train\n",
      "13 | test_hit_rate@5   | MeanMetric    | 0      | train\n",
      "14 | test_hit_rate@20  | MeanMetric    | 0      | train\n",
      "15 | test_mces@1       | MeanMetric    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "694 K     Trainable params\n",
      "0         Non-trainable params\n",
      "694 K     Total params\n",
      "2.778     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "16        Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Train dataset size: 11883\n",
      "Val dataset size: 1899\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in collate_fn\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  7.53it/s]in collate_fn\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] in collate_fn\n",
      "Epoch 0:  50%|█████     | 1/2 [00:07<00:07,  0.13it/s, v_num=fosx]in collate_fn\n",
      "Epoch 0: 100%|██████████| 2/2 [00:18<00:00,  0.11it/s, v_num=fosx, train_loss=0.295]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 11.42it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:10<00:00,  0.18it/s]\u001B[A\n",
      "Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, v_num=fosx, train_loss=0.290, val_loss=0.289]        in collate_fn\n",
      "in collate_fn                                                              ss=0.290, val_loss=0.289]\n",
      "Epoch 1: 100%|██████████| 2/2 [00:24<00:00,  0.08it/s, v_num=fosx, train_loss=0.279, val_loss=0.289]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 11.43it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:11<00:00,  0.18it/s]\u001B[A\n",
      "Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, v_num=fosx, train_loss=0.277, val_loss=0.278]        in collate_fn\n",
      "Epoch 2:  50%|█████     | 1/2 [00:07<00:07,  0.13it/s, v_num=fosx, train_loss=0.277, val_loss=0.278]in collate_fn\n",
      "Epoch 2: 100%|██████████| 2/2 [00:18<00:00,  0.11it/s, v_num=fosx, train_loss=0.271, val_loss=0.278]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 11.50it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:11<00:00,  0.18it/s]\u001B[A\n",
      "Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, v_num=fosx, train_loss=0.269, val_loss=0.267]        in collate_fn\n",
      "Epoch 3:  50%|█████     | 1/2 [00:07<00:07,  0.13it/s, v_num=fosx, train_loss=0.269, val_loss=0.267]in collate_fn\n",
      "Epoch 3: 100%|██████████| 2/2 [00:18<00:00,  0.11it/s, v_num=fosx, train_loss=0.262, val_loss=0.267]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 11.73it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:11<00:00,  0.17it/s]\u001B[A\n",
      "Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, v_num=fosx, train_loss=0.256, val_loss=0.256]        in collate_fn\n",
      "Epoch 4:  50%|█████     | 1/2 [00:07<00:07,  0.13it/s, v_num=fosx, train_loss=0.256, val_loss=0.256]in collate_fn\n",
      "Epoch 4: 100%|██████████| 2/2 [00:21<00:00,  0.09it/s, v_num=fosx, train_loss=0.252, val_loss=0.256]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 11.38it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:12<00:00,  0.16it/s]\u001B[A\n",
      "Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, v_num=fosx, train_loss=0.245, val_loss=0.246]        in collate_fn\n",
      "Epoch 5:  50%|█████     | 1/2 [00:07<00:07,  0.13it/s, v_num=fosx, train_loss=0.245, val_loss=0.246]in collate_fn\n",
      "Epoch 5: 100%|██████████| 2/2 [00:19<00:00,  0.11it/s, v_num=fosx, train_loss=0.241, val_loss=0.246]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 10.84it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:11<00:00,  0.17it/s]\u001B[A\n",
      "Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, v_num=fosx, train_loss=0.238, val_loss=0.236]        in collate_fn\n",
      "Epoch 6:  50%|█████     | 1/2 [00:07<00:07,  0.13it/s, v_num=fosx, train_loss=0.238, val_loss=0.236]in collate_fn\n",
      "Epoch 6: 100%|██████████| 2/2 [00:19<00:00,  0.10it/s, v_num=fosx, train_loss=0.230, val_loss=0.236]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 11.48it/s]\u001B[Ain collate_fn\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:11<00:00,  0.17it/s]\u001B[A\n",
      "Epoch 6: 100%|██████████| 2/2 [00:43<00:00,  0.05it/s, v_num=fosx, train_loss=0.227, val_loss=0.227]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=7` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:43<00:00,  0.05it/s, v_num=fosx, train_loss=0.227, val_loss=0.227]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T06:37:11.364860Z",
     "start_time": "2025-01-15T06:36:52.067768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the model\n",
    "trainer.test(model, datamodule=data_module_msn)"
   ],
   "id": "5371eb8a7483e003",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 1892\n",
      "Testing: |          | 0/? [00:00<?, ?it/s]in collate_fn\n",
      "Testing DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 11.94it/s]in collate_fn\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:11<00:00,  0.17it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_hit_rate@1                0.0\n",
      "    test_hit_rate@20       0.009999999776482582\n",
      "     test_hit_rate@5                0.0\n",
      "        test_loss           0.22103449702262878\n",
      "       test_mces@1          25.790000915527344\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.22103449702262878,\n",
       "  'test_hit_rate@1': 0.0,\n",
       "  'test_hit_rate@5': 0.0,\n",
       "  'test_hit_rate@20': 0.009999999776482582,\n",
       "  'test_mces@1': 25.790000915527344}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T05:29:16.088958Z",
     "start_time": "2025-01-15T05:29:03.500565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model from a specific checkpoint\n",
    "from phantoms.models.retrieval.gnn_retrieval_model import GNNRetrievalModel\n",
    "\n",
    "checkpoint_path = \"/Users/macbook/CODE/PhantoMS/notebooks/checkpoints/gnn_retrieval-epoch=04-val_loss=0.31.ckpt\"\n",
    "model = GNNRetrievalModel.load_from_checkpoint(checkpoint_path)"
   ],
   "id": "5ac2c5809e4de0c8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
