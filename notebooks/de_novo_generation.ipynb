{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T09:03:48.714720Z",
     "start_time": "2025-02-01T09:03:46.224860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "from massspecgym.data.datasets import MSnDataset\n",
    "from massspecgym.featurize import SpectrumFeaturizer\n",
    "from massspecgym.data import RetrievalDataset, MassSpecDataModule\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import typing as T\n",
    "from typing import List, Optional\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "from massspecgym.models.base import Stage\n",
    "from massspecgym.models.de_novo.base import DeNovoMassSpecGymModel\n",
    "\n",
    "from phantoms.utils.custom_tokenizers import ByteBPETokenizerWithSpecialTokens\n",
    "from phantoms.utils.constants import PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN\n",
    "\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer"
   ],
   "id": "64795c335ce9b8cf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-01T09:03:48.720348Z",
     "start_time": "2025-02-01T09:03:48.717356Z"
    }
   },
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard sinusoidal positional encoding as in \"Attention is All You Need\".\n",
    "    Expects shape [seq_len, batch_size, d_model] if batch_first=False.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # shape becomes [max_len, d_model]\n",
    "\n",
    "        pe = pe.unsqueeze(1)  # [max_len, 1, d_model]\n",
    "        self.register_buffer(\"pe\", pe)  # not a learnable parameter\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: [seq_len, batch_size, d_model]\n",
    "        Returns the input plus positional encodings.\n",
    "        \"\"\"\n",
    "        seq_len = x.size(0)\n",
    "        # Add the encoding only up to seq_len\n",
    "        # self.pe[:seq_len] is [seq_len, 1, d_model]\n",
    "        return x + self.pe[:seq_len]\n",
    "\n",
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, smiles_list, tokenizer, max_len=200):\n",
    "        self.smiles_list = smiles_list\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.smiles_list[idx]\n",
    "        # Encode the text with special tokens (the post-processor adds SOS and EOS)\n",
    "        token_ids = self.tokenizer.encode(text, add_special_tokens=True)\n",
    "        # Truncate if necessary\n",
    "        token_ids = token_ids[:self.max_len]\n",
    "        # For teacher forcing, input is all tokens except the last,\n",
    "        # target is all tokens except the first.\n",
    "        input_ids = token_ids[:-1]\n",
    "        target_ids = token_ids[1:]\n",
    "        return {\n",
    "            \"input\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"target\": torch.tensor(target_ids, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class SMILESLanguageModel(pl.LightningModule):\n",
    "    def __init__(self, vocab_size: int, d_model: int = 256, nhead: int = 4,\n",
    "                 num_decoder_layers: int = 4, dropout: float = 0.1,\n",
    "                 pad_token_id: int = 0, max_len: int = 200):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        decoder_layer = TransformerDecoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=4*d_model,\n",
    "            dropout=dropout, activation=\"relu\", batch_first=False\n",
    "        )\n",
    "        self.decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "        self.pos_encoder = PositionalEncoding(d_model=d_model, max_len=max_len)\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_token_id)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
    "    def forward(self, tgt_input):\n",
    "        # tgt_input: [seq_len, batch]\n",
    "        emb = self.embedding(tgt_input) * math.sqrt(self.d_model)\n",
    "        emb = self.pos_encoder(emb)\n",
    "        batch = tgt_input.size(1)\n",
    "        # For standalone LM, we can use a zero \"memory\"\n",
    "        memory = torch.zeros(1, batch, self.d_model, device=tgt_input.device)\n",
    "        seq_len = tgt_input.size(0)\n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len, dtype=torch.bool, device=tgt_input.device), diagonal=1)\n",
    "        output = self.decoder(tgt=emb, memory=memory, tgt_mask=causal_mask)\n",
    "        logits = self.fc_out(output)\n",
    "        return logits\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch[\"input\"])  # [seq_len, batch, vocab_size]\n",
    "        loss = self.criterion(logits.view(-1, logits.size(-1)), batch[\"target\"].view(-1))\n",
    "        self.log(\"loss\", loss)\n",
    "        return loss\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "# Full model: GATDeNovoTransformer (same as you provided)\n",
    "class GATDeNovoTransformer(DeNovoMassSpecGymModel):\n",
    "    \"\"\"\n",
    "    Example GAT -> (single embedding) -> Transformer Decoder for SMILES generation.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        d_model: int = 256,\n",
    "        nhead: int = 4,\n",
    "        num_gat_layers: int = 3,\n",
    "        num_decoder_layers: int = 4,\n",
    "        num_gat_heads: int = 4,\n",
    "        gat_dropout: float = 0.6,\n",
    "        smiles_tokenizer: ByteBPETokenizerWithSpecialTokens = None,\n",
    "        start_token: str = SOS_TOKEN,\n",
    "        end_token: str = EOS_TOKEN,\n",
    "        pad_token: str = PAD_TOKEN,\n",
    "        unk_token: str = UNK_TOKEN,\n",
    "        dropout: float = 0.1,\n",
    "        max_smiles_len: int = 200,\n",
    "        k_predictions: int = 1,\n",
    "        temperature: T.Optional[float] = 1.0,\n",
    "        pre_norm: bool = False,\n",
    "        chemical_formula: bool = False,\n",
    "        log_only_loss_at_stages: Optional[list] = [Stage.TRAIN],\n",
    "        *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(log_only_loss_at_stages=log_only_loss_at_stages, *args, **kwargs)\n",
    "        if smiles_tokenizer is None:\n",
    "            raise ValueError(\"Must provide a ByteBPETokenizerWithSpecialTokens instance.\")\n",
    "        self.smiles_tokenizer = smiles_tokenizer\n",
    "        self.vocab_size = self.smiles_tokenizer.get_vocab_size()\n",
    "\n",
    "        for tok in [start_token, end_token, pad_token, unk_token]:\n",
    "            if tok not in self.smiles_tokenizer.get_vocab():\n",
    "                raise ValueError(f\"Special token '{tok}' not in tokenizer vocab\")\n",
    "\n",
    "        self.start_token_id = self.smiles_tokenizer.token_to_id(start_token)\n",
    "        self.end_token_id   = self.smiles_tokenizer.token_to_id(end_token)\n",
    "        self.pad_token_id   = self.smiles_tokenizer.token_to_id(pad_token)\n",
    "        self.unk_token_id   = self.smiles_tokenizer.token_to_id(unk_token)\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.max_smiles_len = max_smiles_len\n",
    "        self.k_predictions = k_predictions\n",
    "        self.temperature = temperature if k_predictions > 1 else None\n",
    "        self.chemical_formula = chemical_formula\n",
    "\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        self.gat_layers.append(\n",
    "            GATConv(\n",
    "                in_channels=input_dim,\n",
    "                out_channels=d_model // num_gat_heads,\n",
    "                heads=num_gat_heads,\n",
    "                dropout=gat_dropout,\n",
    "                add_self_loops=True\n",
    "            )\n",
    "        )\n",
    "        for _ in range(num_gat_layers - 1):\n",
    "            self.gat_layers.append(\n",
    "                GATConv(\n",
    "                    in_channels=d_model,\n",
    "                    out_channels=d_model // num_gat_heads,\n",
    "                    heads=num_gat_heads,\n",
    "                    dropout=gat_dropout,\n",
    "                    add_self_loops=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.encoder_fc = nn.Linear(d_model, d_model)\n",
    "        if self.chemical_formula:\n",
    "            self.formula_mlp = nn.Sequential(\n",
    "                nn.Linear(128, d_model),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_model, d_model),\n",
    "            )\n",
    "\n",
    "        decoder_layer = TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            dropout=dropout,\n",
    "            activation=\"relu\",\n",
    "            batch_first=False,\n",
    "            norm_first=pre_norm\n",
    "        )\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "        self.pos_encoder = PositionalEncoding(d_model=d_model, max_len=max_smiles_len)\n",
    "        self.decoder_embed = nn.Embedding(self.vocab_size, d_model, padding_idx=self.pad_token_id)\n",
    "        self.decoder_fc = nn.Linear(d_model, self.vocab_size)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=self.pad_token_id)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.encoder_fc.weight)\n",
    "        nn.init.zeros_(self.encoder_fc.bias)\n",
    "        nn.init.normal_(self.decoder_embed.weight, mean=0, std=self.d_model**-0.5)\n",
    "        nn.init.xavier_uniform_(self.decoder_fc.weight)\n",
    "        nn.init.zeros_(self.decoder_fc.bias)\n",
    "\n",
    "    def step(self, batch: dict, stage: Stage = Stage.NONE) -> dict:\n",
    "        output_dict = self.forward(batch)\n",
    "        loss = output_dict[\"loss\"]\n",
    "        self.log(\n",
    "            f\"{stage.to_pref()}loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=batch[\"spec\"].num_graphs,\n",
    "        )\n",
    "        if stage not in self.log_only_loss_at_stages:\n",
    "            mols_pred = self.decode_smiles(batch)\n",
    "            output_dict[\"mols_pred\"] = mols_pred\n",
    "        else:\n",
    "            output_dict[\"mols_pred\"] = None\n",
    "        return output_dict\n",
    "\n",
    "    def forward(self, batch: dict) -> dict:\n",
    "        spec = batch[\"spec\"]\n",
    "        smiles_list = batch[\"mol\"]\n",
    "        x, edge_index, batch_idx = spec.x, spec.edge_index, spec.batch\n",
    "        for gat in self.gat_layers:\n",
    "            x = gat(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "        x = global_mean_pool(x, batch_idx)\n",
    "        if self.chemical_formula and (\"formula\" in batch):\n",
    "            formula = batch[\"formula\"].float().to(x.device)\n",
    "            x = x + self.formula_mlp(formula)\n",
    "        memory = self.encoder_fc(x)\n",
    "        memory = memory.unsqueeze(0)  # [1, batch, d_model]\n",
    "\n",
    "        encoded_smiles = self.smiles_tokenizer.encode_batch(smiles_list)\n",
    "        smiles_ids = torch.tensor(encoded_smiles, dtype=torch.long, device=x.device)\n",
    "        tgt_input  = smiles_ids[:, :-1]\n",
    "        tgt_output = smiles_ids[:, 1:]\n",
    "        tgt_input  = tgt_input.transpose(0, 1).contiguous()\n",
    "        tgt_output = tgt_output.transpose(0, 1).contiguous()\n",
    "        tgt_key_padding_mask = (tgt_input == self.pad_token_id).transpose(0, 1)\n",
    "        tgt_embed = self.decoder_embed(tgt_input) * math.sqrt(self.d_model)\n",
    "        tgt_embed = self.pos_encoder(tgt_embed)\n",
    "        tgt_len = tgt_input.size(0)\n",
    "        causal_mask = self._generate_square_subsequent_mask(tgt_len).to(tgt_embed.device)\n",
    "        decoded = self.transformer_decoder(\n",
    "            tgt=tgt_embed,\n",
    "            memory=memory,\n",
    "            tgt_mask=causal_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "        logits = self.decoder_fc(decoded)\n",
    "        logits = logits.transpose(0, 1).contiguous()\n",
    "        tgt_output = tgt_output.transpose(0, 1).contiguous()\n",
    "        loss = self.criterion(logits.view(-1, self.vocab_size), tgt_output.view(-1))\n",
    "        return dict(loss=loss)\n",
    "\n",
    "    def decode_smiles(self, batch: dict) -> List[List[str]]:\n",
    "        spec = batch[\"spec\"]\n",
    "        x, edge_index, batch_idx = spec.x, spec.edge_index, spec.batch\n",
    "        for gat in self.gat_layers:\n",
    "            x = gat(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "        x = global_mean_pool(x, batch_idx)\n",
    "        if self.chemical_formula and (\"formula\" in batch):\n",
    "            formula = batch[\"formula\"].float().to(x.device)\n",
    "            x = x + self.formula_mlp(formula)\n",
    "        memory = self.encoder_fc(x).unsqueeze(0)\n",
    "        batch_size = memory.size(1)\n",
    "        device = memory.device\n",
    "        all_decoded_smiles = [[] for _ in range(batch_size)]\n",
    "        for _ in range(self.k_predictions):\n",
    "            generated_tokens = torch.full((1, batch_size), self.start_token_id,\n",
    "                                           dtype=torch.long, device=device)\n",
    "            finished = [False]*batch_size\n",
    "            decoded_sequences: List[List[int]] = [[] for _ in range(batch_size)]\n",
    "            for step in range(self.max_smiles_len):\n",
    "                tgt_embed = self.decoder_embed(generated_tokens) * math.sqrt(self.d_model)\n",
    "                tgt_embed = self.pos_encoder(tgt_embed)\n",
    "                tgt_len = tgt_embed.size(0)\n",
    "                causal_mask = self._generate_square_subsequent_mask(tgt_len).to(device)\n",
    "                output = self.transformer_decoder(\n",
    "                    tgt=tgt_embed,\n",
    "                    memory=memory,\n",
    "                    tgt_mask=causal_mask\n",
    "                )\n",
    "                last_logits = self.decoder_fc(output[-1])\n",
    "                if self.temperature is None:\n",
    "                    next_token = torch.argmax(last_logits, dim=-1)\n",
    "                else:\n",
    "                    probs = F.softmax(last_logits / self.temperature, dim=-1)\n",
    "                    next_token = torch.multinomial(probs, num_samples=1).squeeze(-1)\n",
    "                next_token = next_token.unsqueeze(0)\n",
    "                generated_tokens = torch.cat([generated_tokens, next_token], dim=0)\n",
    "                for i in range(batch_size):\n",
    "                    if not finished[i]:\n",
    "                        token_id = next_token[0, i].item()\n",
    "                        if token_id == self.end_token_id:\n",
    "                            finished[i] = True\n",
    "                        else:\n",
    "                            decoded_sequences[i].append(token_id)\n",
    "                if all(finished):\n",
    "                    break\n",
    "            batch_smiles = []\n",
    "            for seq_ids in decoded_sequences:\n",
    "                text = self.smiles_tokenizer.decode(seq_ids, skip_special_tokens=True)\n",
    "                batch_smiles.append(text)\n",
    "            for i in range(batch_size):\n",
    "                all_decoded_smiles[i].append(batch_smiles[i])\n",
    "        return all_decoded_smiles\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz: int) -> torch.Tensor:\n",
    "        return torch.triu(torch.ones(sz, sz, dtype=torch.bool), diagonal=1)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "spectra_mgf = \"/Users/macbook/CODE/Majer:MassSpecGym/data/MSn/min_sample_trees.mgf\"\n",
    "split_file = \"/Users/macbook/CODE/Majer:MassSpecGym/data/MSn/20241211_split.tsv\""
   ],
   "id": "b81494b637fbf846"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "split_file = \"/Users/macbook/CODE/Majer:MassSpecGym/data/MSn/20241211_split.tsv\"\n",
    "config = {\n",
    "    'features': ['binned_peaks'],\n",
    "    'feature_attributes': {\n",
    "        'binned_peaks': {\n",
    "            'max_mz': 1000,\n",
    "            'bin_width': 0.25,\n",
    "            'to_rel_intensities': True,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "featurizer = SpectrumFeaturizer(config, mode='torch')\n",
    "batch_size = 12\n",
    "input_dim = 4000"
   ],
   "id": "fee0ccc905710dd8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "msn_dataset = MSnDataset(\n",
    "    pth=spectra_mgf,\n",
    "    featurizer=featurizer,\n",
    "    mol_transform=None,\n",
    "    max_allowed_deviation=0.005\n",
    ")"
   ],
   "id": "1bed961f9ccccb53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_module_msn = MassSpecDataModule(\n",
    "    dataset=msn_dataset,\n",
    "    batch_size=batch_size,\n",
    "    split_pth=split_file,\n",
    "    num_workers=0,\n",
    ")"
   ],
   "id": "e1cd1d99545d65ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SMILES_TOKENIZER_SAVE_PATH = \"/Users/macbook/CODE/Majer:MassSpecGym/data/tokenizers/smiles_tokenizer.json\"\n",
    "smiles_tokenizer = ByteBPETokenizerWithSpecialTokens(tokenizer_path=SMILES_TOKENIZER_SAVE_PATH)"
   ],
   "id": "419dfea34462c58f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "smiles_data = msn_dataset.smiles",
   "id": "8217b7f5c689813a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create the dataset and dataloader\n",
    "pretrain_dataset = SMILESDataset(smiles_data, smiles_tokenizer, max_len=200)\n",
    "pretrain_dataloader = DataLoader(\n",
    "    pretrain_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda batch: {\n",
    "        \"input\": torch.nn.utils.rnn.pad_sequence(\n",
    "            [item[\"input\"] for item in batch], batch_first=False, padding_value=smiles_tokenizer.token_to_id(PAD_TOKEN)\n",
    "        ),\n",
    "        \"target\": torch.nn.utils.rnn.pad_sequence(\n",
    "            [item[\"target\"] for item in batch], batch_first=False, padding_value=smiles_tokenizer.token_to_id(PAD_TOKEN)\n",
    "        )\n",
    "    }\n",
    ")"
   ],
   "id": "bccb8f6636ffbe2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create the language model\n",
    "vocab_size = smiles_tokenizer.get_vocab_size()\n",
    "model_pretrain = SMILESLanguageModel(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=256,\n",
    "    nhead=4,\n",
    "    num_decoder_layers=4,\n",
    "    dropout=0.1,\n",
    "    pad_token_id=smiles_tokenizer.token_to_id(PAD_TOKEN),\n",
    "    max_len=200\n",
    ")\n",
    "\n",
    "# Train using PyTorch Lightning Trainer\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"cpu\", devices=1)  # adjust as available\n",
    "trainer.fit(model_pretrain, pretrain_dataloader)\n",
    "\n",
    "# Save the pretrained weights\n",
    "torch.save(model_pretrain.state_dict(), \"smiles_decoder_pretrained.pth\")\n",
    "print(\"Pretraining complete and weights saved.\")"
   ],
   "id": "88c7d7abf48d7a93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_full = GATDeNovoTransformer(\n",
    "    input_dim=input_dim,  # example feature dimension from your spec.x shape\n",
    "    d_model=256,\n",
    "    nhead=4,\n",
    "    num_gat_layers=3,\n",
    "    num_decoder_layers=4,\n",
    "    num_gat_heads=4,\n",
    "    gat_dropout=0.6,\n",
    "    smiles_tokenizer=smiles_tokenizer,\n",
    "    dropout=0.1,\n",
    "    max_smiles_len=200,\n",
    "    k_predictions=1,\n",
    "    temperature=1.0,\n",
    "    pre_norm=False,\n",
    "    chemical_formula=False\n",
    ")"
   ],
   "id": "7d45288ce4d74445"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load pretrained decoder weights into the full model\n",
    "pretrained_dict = torch.load(\"smiles_decoder_pretrained.pth\", map_location=\"cpu\")\n",
    "model_dict = model_full.state_dict()"
   ],
   "id": "992a92904530432"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Only update the decoder-related parts (keys matching \"decoder\", \"pos_encoder\", \"decoder_embed\", \"decoder_fc\")\n",
    "pretrained_keys = {k: v for k, v in pretrained_dict.items() if k in model_dict and (\"decoder\" in k or \"pos_encoder\" in k or \"embedding\" in k or \"fc_out\" in k or \"decoder_embed\" in k or \"decoder_fc\" in k)}\n",
    "model_dict.update(pretrained_keys)\n",
    "model_full.load_state_dict(model_dict)\n",
    "print(\"Loaded pretrained decoder weights into the full model.\")"
   ],
   "id": "627871a19cb582ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "tb_logger = TensorBoardLogger(\"logs\", name=\"gat_de_novo_transformer\")\n",
    "trainer_full = Trainer(\n",
    "    accelerator=\"cpu\",                # Change to \"gpu\" if available\n",
    "    devices=1,\n",
    "    max_epochs=2,                     # Adjust as needed\n",
    "    log_every_n_steps=10,\n",
    "    limit_train_batches=2,\n",
    "    limit_val_batches=2,\n",
    "    limit_test_batches=2,\n",
    "    logger=tb_logger,\n",
    ")"
   ],
   "id": "31a6464e8042593d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer_full.fit(model_full, datamodule=data_module_msn)",
   "id": "8c1ae06d4116d418"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer_full.test(model_full, datamodule=data_module_msn)",
   "id": "311c2c3e6237e31b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5237b364953da2d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fc91ed5a70fac3af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f923598458b98f01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T09:03:50.193176Z",
     "start_time": "2025-02-01T09:03:50.125701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import typing as T\n",
    "# from torch_geometric.nn import GATConv, global_mean_pool\n",
    "#\n",
    "# from massspecgym.models.base import Stage\n",
    "# from massspecgym.models.de_novo.base import DeNovoMassSpecGymModel\n",
    "#\n",
    "# # Adjust import paths if needed:\n",
    "# from phantoms.utils.custom_tokenizers import ByteBPETokenizerWithSpecialTokens\n",
    "# from phantoms.utils.constants import PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN\n",
    "#\n",
    "# from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
    "\n",
    "class GATDeNovoTransformer(DeNovoMassSpecGymModel):\n",
    "    \"\"\"\n",
    "    Example GAT -> (single embedding) -> Transformer Decoder for SMILES generation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,              # node feature dimension\n",
    "        d_model: int = 256,\n",
    "        nhead: int = 4,\n",
    "        num_gat_layers: int = 3,\n",
    "        num_decoder_layers: int = 4,\n",
    "        num_gat_heads: int = 4,\n",
    "        gat_dropout: float = 0.6,\n",
    "        smiles_tokenizer: ByteBPETokenizerWithSpecialTokens = None,\n",
    "        start_token: str = SOS_TOKEN,\n",
    "        end_token: str = EOS_TOKEN,\n",
    "        pad_token: str = PAD_TOKEN,\n",
    "        unk_token: str = UNK_TOKEN,\n",
    "        dropout: float = 0.1,\n",
    "        max_smiles_len: int = 200,\n",
    "        k_predictions: int = 1,\n",
    "        temperature: T.Optional[float] = 1.0,\n",
    "        pre_norm: bool = False,\n",
    "        chemical_formula: bool = False,\n",
    "        *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # ------------------------------\n",
    "        #  1) SMILES Tokenizer\n",
    "        # ------------------------------\n",
    "        if smiles_tokenizer is None:\n",
    "            raise ValueError(\"Must provide a ByteBPETokenizerWithSpecialTokens instance.\")\n",
    "        self.smiles_tokenizer = smiles_tokenizer\n",
    "        self.vocab_size = self.smiles_tokenizer.get_vocab_size()\n",
    "\n",
    "        # Make sure special tokens exist in vocab\n",
    "        for tok in [start_token, end_token, pad_token, unk_token]:\n",
    "            if tok not in self.smiles_tokenizer.get_vocab():\n",
    "                raise ValueError(f\"Special token '{tok}' not in tokenizer vocab\")\n",
    "\n",
    "        # IDs\n",
    "        self.start_token_id = self.smiles_tokenizer.token_to_id(start_token)\n",
    "        self.end_token_id   = self.smiles_tokenizer.token_to_id(end_token)\n",
    "        self.pad_token_id   = self.smiles_tokenizer.token_to_id(pad_token)\n",
    "        self.unk_token_id   = self.smiles_tokenizer.token_to_id(unk_token)\n",
    "\n",
    "        # ------------------------------\n",
    "        #  2) Hyperparams\n",
    "        # ------------------------------\n",
    "        self.d_model = d_model\n",
    "        self.max_smiles_len = max_smiles_len\n",
    "        self.k_predictions = k_predictions\n",
    "        self.temperature = temperature if k_predictions > 1 else None\n",
    "        self.chemical_formula = chemical_formula\n",
    "\n",
    "        # ------------------------------\n",
    "        #  3) GAT Encoder\n",
    "        # ------------------------------\n",
    "        # We'll build a stack of GATConv => ELU\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "\n",
    "        # first layer\n",
    "        self.gat_layers.append(\n",
    "            GATConv(\n",
    "                in_channels=input_dim,\n",
    "                out_channels=d_model // num_gat_heads,\n",
    "                heads=num_gat_heads,\n",
    "                dropout=gat_dropout,\n",
    "                add_self_loops=True\n",
    "            )\n",
    "        )\n",
    "        # subsequent layers\n",
    "        for _ in range(num_gat_layers - 1):\n",
    "            self.gat_layers.append(\n",
    "                GATConv(\n",
    "                    in_channels=d_model,  # after heads, we combine into d_model\n",
    "                    out_channels=d_model // num_gat_heads,\n",
    "                    heads=num_gat_heads,\n",
    "                    dropout=gat_dropout,\n",
    "                    add_self_loops=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # ------------------------------\n",
    "        #  4) Projection to d_model\n",
    "        # ------------------------------\n",
    "        self.encoder_fc = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # If you want formula => embed => add in:\n",
    "        if self.chemical_formula:\n",
    "            # Suppose formula is 128-dim or something\n",
    "            self.formula_mlp = nn.Sequential(\n",
    "                nn.Linear(128, d_model),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_model, d_model),\n",
    "            )\n",
    "\n",
    "        # ------------------------------\n",
    "        #  5) Transformer Decoder\n",
    "        # ------------------------------\n",
    "        # We'll define a standard TransformerDecoder of `num_decoder_layers`\n",
    "        decoder_layer = TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            dropout=dropout,\n",
    "            activation=\"relu\",\n",
    "            batch_first=False,     # By default PyTorch uses seq_first\n",
    "            norm_first=pre_norm\n",
    "        )\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model=d_model, max_len=max_smiles_len)\n",
    "\n",
    "        # Embeddings and final projection for SMILES tokens\n",
    "        self.decoder_embed = nn.Embedding(self.vocab_size, d_model, padding_idx=self.pad_token_id)\n",
    "        self.decoder_fc = nn.Linear(d_model, self.vocab_size)\n",
    "\n",
    "        # We use a standard CE loss ignoring the pad index\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=self.pad_token_id)\n",
    "\n",
    "        # init weights\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.encoder_fc.weight)\n",
    "        nn.init.zeros_(self.encoder_fc.bias)\n",
    "\n",
    "        nn.init.normal_(self.decoder_embed.weight, mean=0, std=self.d_model**-0.5)\n",
    "        nn.init.xavier_uniform_(self.decoder_fc.weight)\n",
    "        nn.init.zeros_(self.decoder_fc.bias)\n",
    "\n",
    "    # ------------------------------\n",
    "    #  TRAINING/VAL/TEST STEPS\n",
    "    # ------------------------------\n",
    "    def step(self, batch: dict, stage: Stage = Stage.NONE) -> dict:\n",
    "        \"\"\"\n",
    "        Mandatory method from base:\n",
    "          - forward pass,\n",
    "          - compute loss,\n",
    "          - optionally decode molecules.\n",
    "        \"\"\"\n",
    "        print(\"running\")\n",
    "        output_dict = self.forward(batch)\n",
    "        print(\"running\")\n",
    "        loss = output_dict[\"loss\"]\n",
    "\n",
    "        # Log the loss\n",
    "        self.log(\n",
    "            f\"{stage.to_pref()}loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            batch_size=batch[\"spec\"].num_graphs,  # or batch['spec'].size(0) if you do that\n",
    "        )\n",
    "        print(\"running\")\n",
    "\n",
    "        # For steps where we want metrics, set `mols_pred` so we can evaluate\n",
    "        if stage not in self.log_only_loss_at_stages:\n",
    "            mols_pred = self.decode_smiles(batch)  # or do beam if k_predictions>1\n",
    "            output_dict[\"mols_pred\"] = mols_pred\n",
    "        else:\n",
    "            output_dict[\"mols_pred\"] = None\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "    def forward(self, batch: dict) -> dict:\n",
    "        \"\"\"\n",
    "        1) GAT-encode MSn trees => single [batch_size, d_model].\n",
    "        2) Teacher-forcing the SMILES decoder => compute CE loss.\n",
    "        \"\"\"\n",
    "        spec = batch[\"spec\"]  # PyG DataBatch: .x, .edge_index, .batch\n",
    "        smiles_list = batch[\"mol\"]  # list of SMILES strings\n",
    "\n",
    "        # ------------------------------\n",
    "        #  1) GAT ENCODER\n",
    "        # ------------------------------\n",
    "        x, edge_index, batch_idx = spec.x, spec.edge_index, spec.batch\n",
    "        # optional: debug shape\n",
    "        # print(\"x shape: \", x.shape, \"edge_index shape: \", edge_index.shape)\n",
    "\n",
    "        for layer_idx, gat in enumerate(self.gat_layers):\n",
    "            x = gat(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "\n",
    "        # global mean pool => [batch_size, d_model]\n",
    "        x = global_mean_pool(x, batch_idx)\n",
    "        print(\"running\")\n",
    "        # optional formula\n",
    "        if self.chemical_formula and (\"formula\" in batch):\n",
    "            # Suppose batch[\"formula\"] is shape [batch_size, 128]\n",
    "            formula = batch[\"formula\"].float().to(x.device)\n",
    "            x = x + self.formula_mlp(formula)\n",
    "\n",
    "        # project to exactly d_model (in case it changed shape)\n",
    "        memory = self.encoder_fc(x)  # shape [batch_size, d_model]\n",
    "\n",
    "        # We want shape [S=1, B, D] for the memory\n",
    "        memory = memory.unsqueeze(0)  # => [1, batch_size, d_model]\n",
    "\n",
    "        # ------------------------------\n",
    "        #  2) TOKENIZE SMILES + TEACHER-FORCE\n",
    "        # ------------------------------\n",
    "        encoded_smiles = self.smiles_tokenizer.encode_batch(smiles_list)  # list of lists\n",
    "        # Convert to a padded tensor\n",
    "        # If your ByteBPETokenizer is already applying padding to max_len, you get length = self.max_smiles_len\n",
    "        # shaped [batch_size, seq_len]\n",
    "        smiles_ids = torch.tensor(encoded_smiles, dtype=torch.long, device=x.device)\n",
    "\n",
    "        # We'll do teacher forcing:\n",
    "        #  input to the decoder: [  <s>  token1 token2 ... token_{n-1} ]\n",
    "        #  output to match:      [ token1 token2 ... token_{n-1}  </s> ]\n",
    "        # So let's shift everything by 1\n",
    "        tgt_input  = smiles_ids[:, :-1]  # [batch, seq_len-1]\n",
    "        tgt_output = smiles_ids[:, 1:]   # [batch, seq_len-1]\n",
    "        print(\"running\")\n",
    "        # Transpose to [seq_len-1, batch]\n",
    "        tgt_input  = tgt_input.transpose(0, 1).contiguous()   # => [tgt_len, batch]\n",
    "        tgt_output = tgt_output.transpose(0, 1).contiguous()  # => [tgt_len, batch]\n",
    "\n",
    "        # 2.1) Make a key_padding_mask for shape [batch, tgt_len]\n",
    "        #  True means \"ignore this position\"\n",
    "        tgt_key_padding_mask = (tgt_input == self.pad_token_id).transpose(0, 1)  # => [batch, tgt_len]\n",
    "\n",
    "        # 2.2) Embeddings\n",
    "        tgt_embed = self.decoder_embed(tgt_input) * math.sqrt(self.d_model)\n",
    "        # shape => [tgt_len, batch, d_model]\n",
    "\n",
    "        # 2.3) Positional encoding\n",
    "        tgt_embed = self.pos_encoder(tgt_embed)\n",
    "        print(\"running\")\n",
    "        # 2.4) Subsequent (causal) mask for the decoder\n",
    "        tgt_len = tgt_input.size(0)\n",
    "        causal_mask = self._generate_square_subsequent_mask(tgt_len).to(tgt_embed.device)\n",
    "\n",
    "        # 2.5) Pass through TransformerDecoder\n",
    "        # memory: [1, batch, d_model]\n",
    "        # tgt_embed: [tgt_len, batch, d_model]\n",
    "        decoded = self.transformer_decoder(\n",
    "            tgt=tgt_embed,\n",
    "            memory=memory,\n",
    "            tgt_mask=causal_mask,                 # shape [tgt_len, tgt_len]\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "        # => [tgt_len, batch, d_model]\n",
    "\n",
    "        # 2.6) Final linear\n",
    "        logits = self.decoder_fc(decoded)  # => [tgt_len, batch, vocab_size]\n",
    "\n",
    "        # Flatten for CE loss\n",
    "        logits = logits.transpose(0, 1).contiguous()  # => [batch, tgt_len, vocab_size]\n",
    "        tgt_output = tgt_output.transpose(0, 1).contiguous()  # => [batch, tgt_len]\n",
    "\n",
    "        loss = self.criterion(\n",
    "            logits.view(-1, self.vocab_size),\n",
    "            tgt_output.view(-1)\n",
    "        )\n",
    "\n",
    "        return dict(loss=loss)\n",
    "\n",
    "    # ------------------------------\n",
    "    #  3) GREEDY/TEMPERATURE DECODING\n",
    "    # ------------------------------\n",
    "    def decode_smiles(self, batch: dict) -> list[list[str]]:\n",
    "        \"\"\"\n",
    "        Generate up to k_predictions SMILES for each example in the batch, \n",
    "        returning a nested list of shape [batch_size, k_predictions].\n",
    "        We'll do a simple greedy or top-1 sampling approach here.\n",
    "        \"\"\"\n",
    "        spec = batch[\"spec\"]\n",
    "        x, edge_index, batch_idx = spec.x, spec.edge_index, spec.batch\n",
    "\n",
    "        # Encode GAT\n",
    "        for gat in self.gat_layers:\n",
    "            x = gat(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "        x = global_mean_pool(x, batch_idx)\n",
    "\n",
    "        if self.chemical_formula and (\"formula\" in batch):\n",
    "            formula = batch[\"formula\"].float().to(x.device)\n",
    "            x = x + self.formula_mlp(formula)\n",
    "\n",
    "        memory = self.encoder_fc(x).unsqueeze(0)  # => [1, batch, d_model]\n",
    "\n",
    "        batch_size = memory.size(1)\n",
    "        device = memory.device\n",
    "\n",
    "        # We'll store k decoded sequences per example\n",
    "        all_decoded_smiles = [[] for _ in range(batch_size)]\n",
    "\n",
    "        # For simplicity, do k= self.k_predictions times\n",
    "        for _ in range(self.k_predictions):\n",
    "            # We'll do standard AR decoding up to max_smiles_len\n",
    "            # shape => [1, batch]\n",
    "            generated_tokens = torch.full(\n",
    "                (1, batch_size),\n",
    "                self.start_token_id,\n",
    "                dtype=torch.long,\n",
    "                device=device\n",
    "            )\n",
    "            finished = [False]*batch_size\n",
    "\n",
    "            decoded_sequences: T.List[T.List[int]] = [[] for _ in range(batch_size)]\n",
    "\n",
    "            for step in range(self.max_smiles_len):\n",
    "                tgt_embed = self.decoder_embed(generated_tokens) * math.sqrt(self.d_model)\n",
    "                tgt_embed = self.pos_encoder(tgt_embed)\n",
    "                tgt_len = tgt_embed.size(0)\n",
    "\n",
    "                causal_mask = self._generate_square_subsequent_mask(tgt_len).to(device)\n",
    "\n",
    "                # decode\n",
    "                output = self.transformer_decoder(\n",
    "                    tgt=tgt_embed,\n",
    "                    memory=memory,\n",
    "                    tgt_mask=causal_mask\n",
    "                )\n",
    "                # shape => [tgt_len, batch, d_model]\n",
    "\n",
    "                # final projection for last token\n",
    "                last_logits = self.decoder_fc(output[-1])  # => [batch, vocab_size]\n",
    "\n",
    "                if self.temperature is None:\n",
    "                    # Greedy\n",
    "                    next_token = torch.argmax(last_logits, dim=-1)  # => [batch]\n",
    "                else:\n",
    "                    # Temperature-based sampling\n",
    "                    probs = F.softmax(last_logits / self.temperature, dim=-1)\n",
    "                    next_token = torch.multinomial(probs, num_samples=1).squeeze(-1)\n",
    "\n",
    "                # append\n",
    "                next_token = next_token.unsqueeze(0)  # => [1, batch]\n",
    "                generated_tokens = torch.cat([generated_tokens, next_token], dim=0)\n",
    "\n",
    "                # check if ended\n",
    "                for i in range(batch_size):\n",
    "                    if not finished[i]:\n",
    "                        token_id = next_token[0, i].item()\n",
    "                        if token_id == self.end_token_id:\n",
    "                            finished[i] = True\n",
    "                        else:\n",
    "                            decoded_sequences[i].append(token_id)\n",
    "                if all(finished):\n",
    "                    break\n",
    "\n",
    "            # Now decode into text\n",
    "            # For each item in batch, convert token IDs -> string\n",
    "            batch_smiles = []\n",
    "            for seq_ids in decoded_sequences:\n",
    "                # We decode each token ID into text. \n",
    "                # NOTE: self.smiles_tokenizer.decode expects a *list of IDs for the entire sentence*.\n",
    "                # If your tokenizer merges multiple IDs into subwords, you might get partial fragments.\n",
    "                # But let's do it in one shot:\n",
    "                text = self.smiles_tokenizer.decode(seq_ids, skip_special_tokens=True)\n",
    "                batch_smiles.append(text)\n",
    "\n",
    "            # Store\n",
    "            for i in range(batch_size):\n",
    "                all_decoded_smiles[i].append(batch_smiles[i])\n",
    "\n",
    "        return all_decoded_smiles\n",
    "\n",
    "    # ------------------------------\n",
    "    #  4) Causal Mask Utility\n",
    "    # ------------------------------\n",
    "    def _generate_square_subsequent_mask(self, sz: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        2D causal mask for the target sequence of length sz.\n",
    "        shape => [sz, sz]\n",
    "          True => blocked,  False => allowed\n",
    "        PyTorch's Transformer can accept bool masks with True = no-attend.\n",
    "        \"\"\"\n",
    "        mask = torch.triu(torch.ones(sz, sz, dtype=torch.bool), diagonal=1)\n",
    "        return mask"
   ],
   "id": "cd99e3563f0e039b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T09:03:51.188333Z",
     "start_time": "2025-02-01T09:03:51.183848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SMILES_TOKENIZER_SAVE_PATH = \"/Users/macbook/CODE/Majer:MassSpecGym/data/tokenizers/smiles_tokenizer.json\"\n",
    "smiles_tokenizer = ByteBPETokenizerWithSpecialTokens(tokenizer_path=SMILES_TOKENIZER_SAVE_PATH)"
   ],
   "id": "97388624181fe32e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer from /Users/macbook/CODE/Majer:MassSpecGym/data/tokenizers/smiles_tokenizer.json.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T08:11:46.157725Z",
     "start_time": "2025-02-01T08:11:46.156051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectra_mgf = \"/Users/macbook/CODE/Majer:MassSpecGym/data/MSn/min_sample_trees.mgf\"\n",
    "split_file = \"/Users/macbook/CODE/Majer:MassSpecGym/data/MSn/20241211_split.tsv\""
   ],
   "id": "71f03f723da5369e",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T08:11:46.430608Z",
     "start_time": "2025-02-01T08:11:46.428540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    'features': ['binned_peaks'],\n",
    "    'feature_attributes': {\n",
    "        'binned_peaks': {\n",
    "            'max_mz': 1000,\n",
    "            'bin_width': 0.25,\n",
    "            'to_rel_intensities': True,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "featurizer = SpectrumFeaturizer(config, mode='torch')\n",
    "batch_size = 12"
   ],
   "id": "72409aaec2c71692",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T08:11:47.114141Z",
     "start_time": "2025-02-01T08:11:46.789659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "msn_dataset = MSnDataset(\n",
    "    pth=spectra_mgf,\n",
    "    featurizer=featurizer,\n",
    "    mol_transform=None,\n",
    "    max_allowed_deviation=0.005\n",
    ")"
   ],
   "id": "d4d136f95480ef94",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T08:11:47.118973Z",
     "start_time": "2025-02-01T08:11:47.117099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_module_msn = MassSpecDataModule(\n",
    "    dataset=msn_dataset,\n",
    "    batch_size=batch_size,\n",
    "    split_pth=split_file,\n",
    "    num_workers=0,\n",
    ")"
   ],
   "id": "b7aac4705e5789b0",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T08:11:47.282214Z",
     "start_time": "2025-02-01T08:11:47.212075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dim = 4000  # Update this based on your actual data\n",
    "\n",
    "# Initialize the Model\n",
    "model = GATDeNovoTransformer(\n",
    "    input_dim=input_dim,\n",
    "    d_model=512,\n",
    "    nhead=8,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=6,\n",
    "    num_gat_heads=8,\n",
    "    gat_dropout=0.6,\n",
    "    smiles_tokenizer=smiles_tokenizer,\n",
    "    start_token=SOS_TOKEN,\n",
    "    end_token=EOS_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    unk_token=UNK_TOKEN,\n",
    "    dropout=0.1,\n",
    "    max_smiles_len=200,\n",
    "    k_predictions=1,\n",
    "    temperature=1.0,\n",
    "    pre_norm=False,\n",
    "    chemical_formula=False  # Set to True if incorporating chemical formula embeddings\n",
    ")"
   ],
   "id": "1673f688b87b87fa",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T08:37:56.240164Z",
     "start_time": "2025-02-01T08:37:33.128831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Initialize TensorBoard Logger\n",
    "tb_logger = TensorBoardLogger(\"logs\", name=\"gat_de_novo_transformer\")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\",                # Change to \"gpu\" if available\n",
    "    devices=1,\n",
    "    max_epochs=20,                     # Adjust as needed\n",
    "    log_every_n_steps=10,\n",
    "    limit_train_batches=2,\n",
    "    limit_val_batches=2,\n",
    "    limit_test_batches=2,\n",
    "    logger=tb_logger,\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer.fit(model, datamodule=data_module_msn)\n",
    "\n",
    "# Test the Model\n",
    "trainer.test(model, datamodule=data_module_msn)"
   ],
   "id": "b7e0a8785368bde2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "   | Name                        | Type               | Params | Mode \n",
      "----------------------------------------------------------------------------\n",
      "0  | gat_layers                  | ModuleList         | 2.6 M  | train\n",
      "1  | encoder_fc                  | Linear             | 262 K  | train\n",
      "2  | transformer_decoder         | TransformerDecoder | 25.2 M | train\n",
      "3  | pos_encoder                 | PositionalEncoding | 0      | train\n",
      "4  | decoder_embed               | Embedding          | 317 K  | train\n",
      "5  | decoder_fc                  | Linear             | 318 K  | train\n",
      "6  | criterion                   | CrossEntropyLoss   | 0      | train\n",
      "7  | val_num_valid_mols          | MeanMetric         | 0      | train\n",
      "8  | val_top_1_mces_dist         | MeanMetric         | 0      | train\n",
      "9  | val_top_1_max_tanimoto_sim  | MeanMetric         | 0      | train\n",
      "10 | val_top_1_accuracy          | MeanMetric         | 0      | train\n",
      "11 | val_top_10_mces_dist        | MeanMetric         | 0      | train\n",
      "12 | val_top_10_max_tanimoto_sim | MeanMetric         | 0      | train\n",
      "13 | val_top_10_accuracy         | MeanMetric         | 0      | train\n",
      "----------------------------------------------------------------------------\n",
      "28.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.7 M    Total params\n",
      "114.797   Total estimated model params size (MB)\n",
      "108       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Train dataset size: 82\n",
      "Val dataset size: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "458e2defc3534c7ba9f1d67ddabf0654"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "running\n",
      "running\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:47\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:575\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    569\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    570\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    571\u001B[0m     ckpt_path,\n\u001B[1;32m    572\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    573\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    574\u001B[0m )\n\u001B[0;32m--> 575\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run(model, ckpt_path\u001B[38;5;241m=\u001B[39mckpt_path)\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:982\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    979\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    980\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    981\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 982\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_stage()\n\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1024\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1023\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m isolate_rng():\n\u001B[0;32m-> 1024\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n\u001B[1;32m   1025\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1053\u001B[0m, in \u001B[0;36mTrainer._run_sanity_check\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1052\u001B[0m \u001B[38;5;66;03m# run eval step\u001B[39;00m\n\u001B[0;32m-> 1053\u001B[0m val_loop\u001B[38;5;241m.\u001B[39mrun()\n\u001B[1;32m   1055\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_callback_hooks(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_sanity_check_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py:179\u001B[0m, in \u001B[0;36m_no_grad_context.<locals>._decorator\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context_manager():\n\u001B[0;32m--> 179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loop_run(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:144\u001B[0m, in \u001B[0;36m_EvaluationLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;66;03m# run step hooks\u001B[39;00m\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001B[39;00m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:433\u001B[0m, in \u001B[0;36m_EvaluationLoop._evaluation_step\u001B[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001B[0m\n\u001B[1;32m    428\u001B[0m step_args \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    429\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001B[1;32m    430\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m using_dataloader_iter\n\u001B[1;32m    431\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m (dataloader_iter,)\n\u001B[1;32m    432\u001B[0m )\n\u001B[0;32m--> 433\u001B[0m output \u001B[38;5;241m=\u001B[39m call\u001B[38;5;241m.\u001B[39m_call_strategy_hook(trainer, hook_name, \u001B[38;5;241m*\u001B[39mstep_args)\n\u001B[1;32m    435\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_processed()\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:323\u001B[0m, in \u001B[0;36m_call_strategy_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    322\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 323\u001B[0m     output \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:412\u001B[0m, in \u001B[0;36mStrategy.validation_step\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    411\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_redirection(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation_step\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 412\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module\u001B[38;5;241m.\u001B[39mvalidation_step(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/massspecgym/models/base.py:66\u001B[0m, in \u001B[0;36mMassSpecGymModel.validation_step\u001B[0;34m(self, batch, batch_idx)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalidation_step\u001B[39m(\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28mself\u001B[39m, batch: \u001B[38;5;28mdict\u001B[39m, batch_idx: torch\u001B[38;5;241m.\u001B[39mTensor\n\u001B[1;32m     65\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[torch\u001B[38;5;241m.\u001B[39mTensor, torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m---> 66\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep(batch, stage\u001B[38;5;241m=\u001B[39mStage\u001B[38;5;241m.\u001B[39mVAL)\n",
      "Cell \u001B[0;32mIn[42], line 176\u001B[0m, in \u001B[0;36mGATDeNovoTransformer.step\u001B[0;34m(self, batch, stage)\u001B[0m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stage \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_only_loss_at_stages:\n\u001B[0;32m--> 176\u001B[0m     mols_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecode_smiles(batch)  \u001B[38;5;66;03m# or do beam if k_predictions>1\u001B[39;00m\n\u001B[1;32m    177\u001B[0m     output_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmols_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m mols_pred\n",
      "Cell \u001B[0;32mIn[42], line 329\u001B[0m, in \u001B[0;36mGATDeNovoTransformer.decode_smiles\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    328\u001B[0m \u001B[38;5;66;03m# decode\u001B[39;00m\n\u001B[0;32m--> 329\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer_decoder(\n\u001B[1;32m    330\u001B[0m     tgt\u001B[38;5;241m=\u001B[39mtgt_embed,\n\u001B[1;32m    331\u001B[0m     memory\u001B[38;5;241m=\u001B[39mmemory,\n\u001B[1;32m    332\u001B[0m     tgt_mask\u001B[38;5;241m=\u001B[39mcausal_mask\n\u001B[1;32m    333\u001B[0m )\n\u001B[1;32m    334\u001B[0m \u001B[38;5;66;03m# shape => [tgt_len, batch, d_model]\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;66;03m# final projection for last token\u001B[39;00m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:602\u001B[0m, in \u001B[0;36mTransformerDecoder.forward\u001B[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001B[0m\n\u001B[1;32m    601\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mod \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m--> 602\u001B[0m     output \u001B[38;5;241m=\u001B[39m mod(\n\u001B[1;32m    603\u001B[0m         output,\n\u001B[1;32m    604\u001B[0m         memory,\n\u001B[1;32m    605\u001B[0m         tgt_mask\u001B[38;5;241m=\u001B[39mtgt_mask,\n\u001B[1;32m    606\u001B[0m         memory_mask\u001B[38;5;241m=\u001B[39mmemory_mask,\n\u001B[1;32m    607\u001B[0m         tgt_key_padding_mask\u001B[38;5;241m=\u001B[39mtgt_key_padding_mask,\n\u001B[1;32m    608\u001B[0m         memory_key_padding_mask\u001B[38;5;241m=\u001B[39mmemory_key_padding_mask,\n\u001B[1;32m    609\u001B[0m         tgt_is_causal\u001B[38;5;241m=\u001B[39mtgt_is_causal,\n\u001B[1;32m    610\u001B[0m         memory_is_causal\u001B[38;5;241m=\u001B[39mmemory_is_causal,\n\u001B[1;32m    611\u001B[0m     )\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:1095\u001B[0m, in \u001B[0;36mTransformerDecoderLayer.forward\u001B[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001B[0m\n\u001B[1;32m   1089\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(\n\u001B[1;32m   1090\u001B[0m         x\n\u001B[1;32m   1091\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mha_block(\n\u001B[1;32m   1092\u001B[0m             x, memory, memory_mask, memory_key_padding_mask, memory_is_causal\n\u001B[1;32m   1093\u001B[0m         )\n\u001B[1;32m   1094\u001B[0m     )\n\u001B[0;32m-> 1095\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm3(x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ff_block(x))\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:1140\u001B[0m, in \u001B[0;36mTransformerDecoderLayer._ff_block\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m   1139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_ff_block\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m-> 1140\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear1(x))))\n\u001B[1;32m   1141\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout3(x)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[51], line 20\u001B[0m\n\u001B[1;32m      8\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m      9\u001B[0m     accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m,                \u001B[38;5;66;03m# Change to \"gpu\" if available\u001B[39;00m\n\u001B[1;32m     10\u001B[0m     devices\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     16\u001B[0m     logger\u001B[38;5;241m=\u001B[39mtb_logger,\n\u001B[1;32m     17\u001B[0m )\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Train the Model\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m trainer\u001B[38;5;241m.\u001B[39mfit(model, datamodule\u001B[38;5;241m=\u001B[39mdata_module_msn)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Test the Model\u001B[39;00m\n\u001B[1;32m     23\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtest(model, datamodule\u001B[38;5;241m=\u001B[39mdata_module_msn)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:539\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    538\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 539\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_and_handle_interrupt(\n\u001B[1;32m    540\u001B[0m     \u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001B[1;32m    541\u001B[0m )\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:64\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(launcher, _SubprocessScriptLauncher):\n\u001B[1;32m     63\u001B[0m         launcher\u001B[38;5;241m.\u001B[39mkill(_get_sigkill_signal())\n\u001B[0;32m---> 64\u001B[0m     exit(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n\u001B[1;32m     67\u001B[0m     _interrupt(trainer, exception)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'exit' is not defined"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "33e1e0a035a469f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5aa80e40f791f584"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7476d60a7042f1fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a166ada68e44990e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5d9d5ac90fe2f57d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "545578fa8fa14538"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "db7e1b7386a8d562"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e9c5fccd33d60897"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7eb6e2e74b4e6240"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# def is_valid_smiles(smiles: str) -> bool:\n",
    "#     try:\n",
    "#         mol = Chem.MolFromSmiles(smiles)\n",
    "#         return mol is not None\n",
    "#     except:\n",
    "#         return False\n",
    "# \n",
    "# def calculate_uniqueness(smiles_list: T.List[str]) -> float:\n",
    "#     unique_smiles = set(smiles_list)\n",
    "#     return len(unique_smiles) / len(smiles_list)\n",
    "# \n",
    "# def calculate_novelty(smiles_list: T.List[str], training_set: T.Set[str]) -> float:\n",
    "#     novel_smiles = [smi for smi in smiles_list if smi not in training_set]\n",
    "#     return len(novel_smiles) / len(smiles_list)\n",
    "# \n",
    "# def calculate_diversity(smiles_list: T.List[str]) -> float:\n",
    "#     similarities = []\n",
    "#     for i in range(len(smiles_list)):\n",
    "#         mol1 = Chem.MolFromSmiles(smiles_list[i])\n",
    "#         if mol1 is None:\n",
    "#             continue\n",
    "#         fp1 = Chem.RDKFingerprint(mol1)\n",
    "#         for j in range(i + 1, len(smiles_list)):\n",
    "#             mol2 = Chem.MolFromSmiles(smiles_list[j])\n",
    "#             if mol2 is None:\n",
    "#                 continue\n",
    "#             fp2 = Chem.RDKFingerprint(mol2)\n",
    "#             similarity = TanimotoSimilarity(fp1, fp2)\n",
    "#             similarities.append(similarity)\n",
    "#     if similarities:\n",
    "#         average_similarity = sum(similarities) / len(similarities)\n",
    "#         diversity = 1 - average_similarity  # Higher diversity when lower similarity\n",
    "#     else:\n",
    "#         diversity = 0.0\n",
    "#     return diversity\n",
    "# \n",
    "# def validation_step(self, batch, batch_idx):\n",
    "#     outputs = self.forward(batch)\n",
    "#     loss = outputs['loss']\n",
    "#     self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "# \n",
    "#     if 'mols_pred' in outputs and outputs['mols_pred'] is not None:\n",
    "#         mols_pred = outputs['mols_pred']\n",
    "#         mols_true = batch['mol']\n",
    "# \n",
    "#         # Validity\n",
    "#         valid = [is_valid_smiles(smiles) for smiles in mols_pred]\n",
    "#         validity_score = sum(valid) / len(valid) if valid else 0\n",
    "#         self.log('val_validity', validity_score, on_epoch=True, prog_bar=True)\n",
    "# \n",
    "#         # Uniqueness\n",
    "#         uniqueness_score = calculate_uniqueness(mols_pred)\n",
    "#         self.log('val_uniqueness', uniqueness_score, on_epoch=True, prog_bar=True)\n",
    "# \n",
    "#         # Novelty (requires access to training set)\n",
    "#         # Assuming 'self.training_set' is defined elsewhere in the model\n",
    "#         if hasattr(self, 'training_set') and isinstance(self.training_set, set):\n",
    "#             novelty_score = calculate_novelty(mols_pred, self.training_set)\n",
    "#             self.log('val_novelty', novelty_score, on_epoch=True, prog_bar=True)\n",
    "# \n",
    "#         # Diversity\n",
    "#         diversity_score = calculate_diversity(mols_pred)\n",
    "#         self.log('val_diversity', diversity_score, on_epoch=True, prog_bar=True)\n",
    "# \n",
    "#     return {'val_loss': loss}"
   ],
   "id": "fba43b79b8a0435b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "63beeacff69a25f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "72bf19642f5f1a3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c37c7fe2202ac5aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "89ddd765c71da65f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "727b8cfc60d2f5d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "87a4fa91f4acdc3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a883d881d4a8527d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "894513e83734608"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "73d2f69dbbf47918"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b4f00d33dcc6da65"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
