{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-04T11:09:55.239204Z",
     "start_time": "2025-02-04T11:09:55.236082Z"
    }
   },
   "source": [
    "import yaml\n",
    "from datetime import datetime\n",
    "import os\n",
    "from phantoms.models.denovo.parser import train_decoder\n",
    "from phantoms.utils.parser import train_model, extract_and_save_embeddings, validate_config"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:11:21.432454Z",
     "start_time": "2025-02-04T11:11:21.427557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_path = \"/Users/macbook/CODE/PhantoMS/phantoms/models/denovo/configs/config_decoder_local.yml\"\n",
    "# Load the config\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f) \n",
    "\n",
    "# Set up an experiment folder with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "experiment_folder = os.path.join(\"/Users/macbook/CODE/PhantoMS/experiments_run\",\n",
    "                                 f\"{timestamp}_{config['experiment_base_name']}\")\n"
   ],
   "id": "525a67e3074fb474",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:11:53.114481Z",
     "start_time": "2025-02-04T11:11:24.664584Z"
    }
   },
   "cell_type": "code",
   "source": "train_decoder(config, experiment_folder, config_path)",
   "id": "65da377704ee2c2a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-04_12-11-21_decoder_test/configs/config_decoder_local.yml\n",
      "Training stand-alone molecule decoder.\n",
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mjozefov\u001B[0m (\u001B[33mjozefov-iocb-prague\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250204_121125-qnxteh3j</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/qnxteh3j' target=\"_blank\">2025-02-04_12-11-21_decoder_test</a></strong> to <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/qnxteh3j' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/qnxteh3j</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name        | Type               | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | decoder     | TransformerDecoder | 67.2 M | train\n",
      "1 | pos_encoder | PositionalEncoding | 0      | train\n",
      "2 | embedding   | Embedding          | 303 K  | train\n",
      "3 | fc_out      | Linear             | 303 K  | train\n",
      "4 | criterion   | CrossEntropyLoss   | 0      | train\n",
      "-----------------------------------------------------------\n",
      "67.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "67.8 M    Total params\n",
      "271.173   Total estimated model params size (MB)\n",
      "62        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d10e0a29870149b0a737680bd1553da0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder pretraining complete and weights saved to /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-04_12-11-21_decoder_test/smiles_decoder_pretrained.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁████</td></tr><tr><td>loss</td><td>█▄▃▂▂▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>2.14481</td></tr><tr><td>trainer/global_step</td><td>7</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2025-02-04_12-11-21_decoder_test</strong> at: <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/qnxteh3j' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/qnxteh3j</a><br> View project at: <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250204_121125-qnxteh3j/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train DeNovo",
   "id": "fd9e4c6abd8f67b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:13:31.995406Z",
     "start_time": "2025-02-04T11:13:31.989407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_path = \"/Users/macbook/CODE/PhantoMS/phantoms/models/denovo/configs/config_denovo_local.yml\"\n",
    "\n",
    "# Load configuration.\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "validate_config(config)"
   ],
   "id": "59279255f9bdcffa",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:18:17.816389Z",
     "start_time": "2025-02-04T11:13:32.624016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a unique experiment folder (for logs, checkpoints, configs, etc.)\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "experiment_folder = os.path.join(\"/Users/macbook/CODE/PhantoMS/experiments_run\", f\"{timestamp}_{config['experiment_base_name']}\")\n",
    "\n",
    "# In denovo training we do not need a cut_tree_level (or you may set it to None)\n",
    "cut_tree_level = None\n",
    "\n",
    "# Train the model (this will also initialize the data module, loggers, callbacks, etc.)\n",
    "train_model(config, experiment_folder, config_path, cut_tree_level)"
   ],
   "id": "bf20c9b07556cf0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-04_12-13-32_denovo_test\n",
      "Using de novo task/model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/CODE/PhantoMS/phantoms/utils/parser.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_state = torch.load(config['model'].get('decoder_pretrained_path'), map_location=\"cpu\")\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n",
      "Pretrained decoder weights loaded into GATDeNovoTransformer.\n",
      "Loaded pretrained decoder into de novo model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250204_121333-mbpdj2v7</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/mbpdj2v7' target=\"_blank\">2025-02-04_12-13-32_denovo_test</a></strong> to <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/mbpdj2v7' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/mbpdj2v7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | gat_layers          | ModuleList         | 6.2 M  | train\n",
      "1 | encoder_fc          | Linear             | 1.0 M  | train\n",
      "2 | transformer_decoder | TransformerDecoder | 67.2 M | train\n",
      "3 | pos_encoder         | PositionalEncoding | 0      | train\n",
      "4 | decoder_embed       | Embedding          | 303 K  | train\n",
      "5 | decoder_fc          | Linear             | 303 K  | train\n",
      "6 | criterion           | CrossEntropyLoss   | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "75.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "75.0 M    Total params\n",
      "300.181   Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Train dataset size: 82\n",
      "Val dataset size: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "653c3ba03fef451b8c29f7ddb86705bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "[12:13:41] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6\n",
      "[12:13:41] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6' for input: '������s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6'\n",
      "[12:13:41] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6\n",
      "[12:13:41] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6' for input: '������s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6'\n",
      "[12:13:49] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����\u001D���������������\u0013\u00176�X����\u0013\u0017���\u0013\u0017a�OCCC�\u0013\u0017a�F���6\u0013\u00176\u0013�\u0016��6\u0013\u0017a�\u0013��\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u00036\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013����6@@]�\u0013������6\u0013��6�I\f\u0013���i�������6\u0013��6\n",
      "[12:13:49] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����\u001D���������������\u0013\u00176�X����\u0013\u0017���\u0013\u0017a�OCCC�\u0013\u0017a�F���6\u0013\u00176\u0013�\u0016��6\u0013\u0017a�\u0013��\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u00036\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013����6@@]�\u0013������6\u0013��6�I\f\u0013���i�������6\u0013��6' for input: '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����\u001D���������������\u0013\u00176�X����\u0013\u0017���\u0013\u0017a�OCCC�\u0013\u0017a�F���6\u0013\u00176\u0013�\u0016��6\u0013\u0017a�\u0013��\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u00036\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013����6@@]�\u0013������6\u0013��6�I\f\u0013���i�������6\u0013��6'\n",
      "[12:13:49] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.��a�\u0013���������!\u0013\u0017a@]��\u0013\u00176�X���a\u0013\u0017a�CCOC���6��6\u0016w��\u0016w�\u0013��\u0013��\u0013��\u0013��\u0013�\u0016���6\u0013��\u0013�\u0016w����a\u0013�����a@]�i�6\u0013������i\u0003���\u0013\u001D6\u0013���\u0013��6\u0013���!\u0013���!6���iI�������6���iI\f\u0013���i�����6\u0013����\n",
      "[12:13:49] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.��a�\u0013���������!\u0013\u0017a@]��\u0013\u00176�X���a\u0013\u0017a�CCOC���6��6\u0016w��\u0016w�\u0013��\u0013��\u0013��\u0013��\u0013�\u0016���6\u0013��\u0013�\u0016w����a\u0013�����a@]�i�6\u0013������i\u0003���\u0013\u001D6\u0013���\u0013��6\u0013���!\u0013���!6���iI�������6���iI\f\u0013���i�����6\u0013����' for input: '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.��a�\u0013���������!\u0013\u0017a@]��\u0013\u00176�X���a\u0013\u0017a�CCOC���6��6\u0016w��\u0016w�\u0013��\u0013��\u0013��\u0013��\u0013�\u0016���6\u0013��\u0013�\u0016w����a\u0013�����a@]�i�6\u0013������i\u0003���\u0013\u001D6\u0013���\u0013��6\u0013���!\u0013���!6���iI�������6���iI\f\u0013���i�����6\u0013����'\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bd156bb6a224f7b95a8f16350709829"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c1aab1389cf4bba8744416ae002a596"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:13:58] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[12:13:58] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[12:13:58] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[12:13:58] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[12:14:05] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[12:14:05] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[12:14:05] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[12:14:05] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa9e19643c834459bdda17d6e1ced252"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0fa2747ea604492bf2859f252491f84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        Test metric                 DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_loss                9.61571979522705\n",
      "    test_num_valid_mols                 1.0\n",
      "    test_top_10_accuracy                0.0\n",
      "test_top_10_max_tanimoto_sim    0.03942422196269035\n",
      "   test_top_10_mces_dist               100.0\n",
      "    test_top_1_accuracy                 0.0\n",
      "test_top_1_max_tanimoto_sim     0.03942422196269035\n",
      "    test_top_1_mces_dist               100.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Model saved to /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-04_12-13-32_denovo_test/checkpoints/final_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_num_valid_mols</td><td>▁</td></tr><tr><td>test_top_10_accuracy</td><td>▁</td></tr><tr><td>test_top_10_max_tanimoto_sim</td><td>▁</td></tr><tr><td>test_top_10_mces_dist</td><td>▁</td></tr><tr><td>test_top_1_accuracy</td><td>▁</td></tr><tr><td>test_top_1_max_tanimoto_sim</td><td>▁</td></tr><tr><td>test_top_1_mces_dist</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁▆█</td></tr><tr><td>val_loss</td><td>█▁</td></tr><tr><td>val_num_valid_mols</td><td>▁█</td></tr><tr><td>val_top_10_accuracy</td><td>▁▁</td></tr><tr><td>val_top_10_max_tanimoto_sim</td><td>▁█</td></tr><tr><td>val_top_10_mces_dist</td><td>▁▁</td></tr><tr><td>val_top_1_accuracy</td><td>▁▁</td></tr><tr><td>val_top_1_max_tanimoto_sim</td><td>▁█</td></tr><tr><td>val_top_1_mces_dist</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>test_loss</td><td>9.61572</td></tr><tr><td>test_num_valid_mols</td><td>1</td></tr><tr><td>test_top_10_accuracy</td><td>0</td></tr><tr><td>test_top_10_max_tanimoto_sim</td><td>0.03942</td></tr><tr><td>test_top_10_mces_dist</td><td>100</td></tr><tr><td>test_top_1_accuracy</td><td>0</td></tr><tr><td>test_top_1_max_tanimoto_sim</td><td>0.03942</td></tr><tr><td>test_top_1_mces_dist</td><td>100</td></tr><tr><td>trainer/global_step</td><td>4</td></tr><tr><td>val_loss</td><td>9.14651</td></tr><tr><td>val_num_valid_mols</td><td>1</td></tr><tr><td>val_top_10_accuracy</td><td>0</td></tr><tr><td>val_top_10_max_tanimoto_sim</td><td>0.03433</td></tr><tr><td>val_top_10_mces_dist</td><td>100</td></tr><tr><td>val_top_1_accuracy</td><td>0</td></tr><tr><td>val_top_1_max_tanimoto_sim</td><td>0.03433</td></tr><tr><td>val_top_1_mces_dist</td><td>100</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2025-02-04_12-13-32_denovo_test</strong> at: <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/mbpdj2v7' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/mbpdj2v7</a><br> View project at: <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250204_121333-mbpdj2v7/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-04_12-13-32_denovo_test/configs/config_denovo_local.yml\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:18:32.129309Z",
     "start_time": "2025-02-04T11:18:30.823683Z"
    }
   },
   "cell_type": "code",
   "source": "extract_and_save_embeddings(config, cut_tree_level, experiment_folder)",
   "id": "ef7882a7d0cdffc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings for /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-04_12-13-32_denovo_test\n",
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n",
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 17\n",
      "Embeddings saved to /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-04_12-13-32_denovo_test/embeddings\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bonus De Novo",
   "id": "e7d7daeff67d232a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:18:46.912236Z",
     "start_time": "2025-02-04T11:18:46.905780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_path = \"/Users/macbook/CODE/PhantoMS/phantoms/models/denovo/configs/config_denovo_bonus_local.yml\"\n",
    "\n",
    "# Load configuration.\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "validate_config(config)"
   ],
   "id": "97dbfe35ad356a93",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:23:08.216610Z",
     "start_time": "2025-02-04T11:18:47.633018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a unique experiment folder (for logs, checkpoints, configs, etc.)\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "experiment_folder = os.path.join(\"/Users/macbook/CODE/PhantoMS/experiments_run\", f\"{timestamp}_{config['experiment_base_name']}\")\n",
    "\n",
    "# In denovo training we do not need a cut_tree_level (or you may set it to None)\n",
    "cut_tree_level = None\n",
    "\n",
    "# Train the model (this will also initialize the data module, loggers, callbacks, etc.)\n",
    "train_model(config, experiment_folder, config_path, cut_tree_level)"
   ],
   "id": "d7895aedd7f8a27e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-04_12-18-47_denovo_bonus_test\n",
      "Using de novo task/model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/CODE/PhantoMS/phantoms/utils/parser.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_state = torch.load(config['model'].get('decoder_pretrained_path'), map_location=\"cpu\")\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n",
      "Pretrained decoder weights loaded into GATDeNovoTransformer.\n",
      "Loaded pretrained decoder into de novo model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250204_121848-wka4onx0</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/wka4onx0' target=\"_blank\">2025-02-04_12-18-47_denovo_bonus_test</a></strong> to <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/wka4onx0' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/wka4onx0</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | gat_layers          | ModuleList         | 6.2 M  | train\n",
      "1 | formula_encoder     | Sequential         | 4.9 K  | train\n",
      "2 | encoder_fc          | Linear             | 1.1 M  | train\n",
      "3 | transformer_decoder | TransformerDecoder | 67.2 M | train\n",
      "4 | pos_encoder         | PositionalEncoding | 0      | train\n",
      "5 | decoder_embed       | Embedding          | 303 K  | train\n",
      "6 | decoder_fc          | Linear             | 303 K  | train\n",
      "7 | criterion           | CrossEntropyLoss   | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "75.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "75.1 M    Total params\n",
      "300.462   Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Train dataset size: 82\n",
      "Val dataset size: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "763e0377978c43c0aaf34b9be6f2fb4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc3452511c23456ebca3a113d40c9cdb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4e35bf1c5e64ab1ad90e15f35b226aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:19:14] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[12:19:14] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[12:19:14] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[12:19:14] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[12:19:23] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[12:19:23] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[12:19:23] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[12:19:23] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "356799f8f8a440d9b09614f9ee4aa492"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:19:32] SMILES Parse Error: syntax error while parsing: HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\n",
      "[12:19:32] SMILES Parse Error: Failed parsing SMILES 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH' for input: 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH'\n",
      "[12:19:32] SMILES Parse Error: syntax error while parsing: HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\n",
      "[12:19:32] SMILES Parse Error: Failed parsing SMILES 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH' for input: 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH'\n",
      "[12:19:40] SMILES Parse Error: syntax error while parsing: HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\n",
      "[12:19:40] SMILES Parse Error: Failed parsing SMILES 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH' for input: 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH'\n",
      "[12:19:40] SMILES Parse Error: syntax error while parsing: HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\n",
      "[12:19:40] SMILES Parse Error: Failed parsing SMILES 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH' for input: 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH'\n",
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47c511896bbc462d8d872af7f196bfb5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:21:23] SMILES Parse Error: syntax error while parsing: HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\n",
      "[12:21:23] SMILES Parse Error: Failed parsing SMILES 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH' for input: 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH'\n",
      "[12:21:23] SMILES Parse Error: syntax error while parsing: HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\n",
      "[12:21:23] SMILES Parse Error: Failed parsing SMILES 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH' for input: 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH'\n",
      "[12:23:05] SMILES Parse Error: syntax error while parsing: HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\n",
      "[12:23:05] SMILES Parse Error: Failed parsing SMILES 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH' for input: 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH'\n",
      "[12:23:05] SMILES Parse Error: syntax error while parsing: HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\n",
      "[12:23:05] SMILES Parse Error: Failed parsing SMILES 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH' for input: 'HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        Test metric                 DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_loss               7.691730976104736\n",
      "    test_num_valid_mols                 0.0\n",
      "    test_top_10_accuracy                0.0\n",
      "test_top_10_max_tanimoto_sim            0.0\n",
      "   test_top_10_mces_dist               100.0\n",
      "    test_top_1_accuracy                 0.0\n",
      "test_top_1_max_tanimoto_sim             0.0\n",
      "    test_top_1_mces_dist               100.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Model saved to /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-04_12-18-47_denovo_bonus_test/checkpoints/final_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_num_valid_mols</td><td>▁</td></tr><tr><td>test_top_10_accuracy</td><td>▁</td></tr><tr><td>test_top_10_max_tanimoto_sim</td><td>▁</td></tr><tr><td>test_top_10_mces_dist</td><td>▁</td></tr><tr><td>test_top_1_accuracy</td><td>▁</td></tr><tr><td>test_top_1_max_tanimoto_sim</td><td>▁</td></tr><tr><td>test_top_1_mces_dist</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁▆█</td></tr><tr><td>val_loss</td><td>█▁</td></tr><tr><td>val_num_valid_mols</td><td>▁▁</td></tr><tr><td>val_top_10_accuracy</td><td>▁▁</td></tr><tr><td>val_top_10_max_tanimoto_sim</td><td>▁▁</td></tr><tr><td>val_top_10_mces_dist</td><td>▁▁</td></tr><tr><td>val_top_1_accuracy</td><td>▁▁</td></tr><tr><td>val_top_1_max_tanimoto_sim</td><td>▁▁</td></tr><tr><td>val_top_1_mces_dist</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>test_loss</td><td>7.69173</td></tr><tr><td>test_num_valid_mols</td><td>0</td></tr><tr><td>test_top_10_accuracy</td><td>0</td></tr><tr><td>test_top_10_max_tanimoto_sim</td><td>0</td></tr><tr><td>test_top_10_mces_dist</td><td>100</td></tr><tr><td>test_top_1_accuracy</td><td>0</td></tr><tr><td>test_top_1_max_tanimoto_sim</td><td>0</td></tr><tr><td>test_top_1_mces_dist</td><td>100</td></tr><tr><td>trainer/global_step</td><td>4</td></tr><tr><td>val_loss</td><td>7.36785</td></tr><tr><td>val_num_valid_mols</td><td>0</td></tr><tr><td>val_top_10_accuracy</td><td>0</td></tr><tr><td>val_top_10_max_tanimoto_sim</td><td>0</td></tr><tr><td>val_top_10_mces_dist</td><td>100</td></tr><tr><td>val_top_1_accuracy</td><td>0</td></tr><tr><td>val_top_1_max_tanimoto_sim</td><td>0</td></tr><tr><td>val_top_1_mces_dist</td><td>100</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2025-02-04_12-18-47_denovo_bonus_test</strong> at: <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/wka4onx0' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder/runs/wka4onx0</a><br> View project at: <a href='https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/PhantoMS_Decoder</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250204_121848-wka4onx0/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-04_12-18-47_denovo_bonus_test/configs/config_denovo_bonus_local.yml\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T11:23:09.483950Z",
     "start_time": "2025-02-04T11:23:08.284855Z"
    }
   },
   "cell_type": "code",
   "source": "extract_and_save_embeddings(config, cut_tree_level, experiment_folder)",
   "id": "18be0cb98e7ec58d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings for /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-04_12-18-47_denovo_bonus_test\n",
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n",
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 17\n",
      "Embeddings saved to /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-04_12-18-47_denovo_bonus_test/embeddings\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run multi experiment",
   "id": "fa34ea29a9a674e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:46:30.244439Z",
     "start_time": "2025-02-04T12:46:30.237246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "import yaml\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import List, Optional\n",
    "\n",
    "from phantoms.utils.parser import validate_config, train_model, extract_and_save_embeddings\n",
    "from phantoms.optimizations.training import set_global_seeds\n",
    "\n",
    "def run_all_experiments(config_dir: str,\n",
    "                        experiment_parent_dir: str,\n",
    "                        config_files: List[str],\n",
    "                        cut_tree_levels: Optional[List[int]],\n",
    "                        wandb_project_name: str):\n",
    "    \"\"\"\n",
    "    Iterate over all configuration files and tree levels to run experiments.\n",
    "\n",
    "    Args:\n",
    "        config_dir (str): Directory containing configuration YAML files.\n",
    "        experiment_parent_dir (str): Parent directory to store all experiments.\n",
    "        config_files (List[str]): List of configuration YAML filenames.\n",
    "        cut_tree_levels (Optional[List[int]]): List of cut_tree_at_level values.\n",
    "        wandb_project_name (str): Name of the wandb project.\n",
    "    \"\"\"\n",
    "    # Set global seeds for reproducibility\n",
    "    set_global_seeds(42)\n",
    "\n",
    "    # Create the parent experiment directory if it doesn't exist\n",
    "    os.makedirs(experiment_parent_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over each configuration file\n",
    "    for config_file in config_files:\n",
    "        config_path = os.path.join(config_dir, config_file)\n",
    "\n",
    "        if not os.path.exists(config_path):\n",
    "            print(f\"Configuration file {config_path} does not exist. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Load the configuration\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "\n",
    "        # Validate the configuration\n",
    "        try:\n",
    "            validate_config(config)\n",
    "        except ValueError as ve:\n",
    "            print(f\"Configuration validation error in {config_file}: {ve}\")\n",
    "            continue\n",
    "\n",
    "        # Iterate over each tree level\n",
    "        for level in cut_tree_levels:\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            # Adding a slight sleep to ensure different timestamps\n",
    "            time.sleep(1.0)\n",
    "\n",
    "            # Define a unique experiment folder name\n",
    "            config_name = os.path.splitext(os.path.basename(config_file))[0]\n",
    "            experiment_folder_name = f\"{config_name}_cut_tree_{level}_{timestamp}\"\n",
    "            experiment_folder = os.path.join(experiment_parent_dir, experiment_folder_name)\n",
    "\n",
    "            # Print experiment details for debugging\n",
    "            print(f\"\\nRunning Experiment: {experiment_folder_name}\")\n",
    "            print(f\"W&B Project: {wandb_project_name}\")\n",
    "            print(f\"Cut Tree Level: {level}\")\n",
    "\n",
    "            # Create the experiment folder\n",
    "            os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "            # Modify the config dict's 'trainer.checkpoint_dir' to point to experiment_folder subdirectories\n",
    "            config['trainer']['checkpoint_dir'] = os.path.join(experiment_folder, 'checkpoints')\n",
    "\n",
    "            # Optionally, modify 'experiment_base_name' to include the experiment_folder name or set to a unified value\n",
    "            config['experiment_base_name'] = 'experiment_trial'  # Or any desired base name\n",
    "\n",
    "            # Update W&B project name\n",
    "            config['wandb']['project'] = wandb_project_name\n",
    "\n",
    "            # Train the model\n",
    "            train_model(config, experiment_folder, config_path, level)\n",
    "\n",
    "            # Extract and save embeddings\n",
    "            extract_and_save_embeddings(config, level, experiment_folder)\n",
    "\n",
    "            # Finish the W&B run to ensure it's properly logged\n",
    "            wandb.finish()\n",
    "\n",
    "    print(\"\\nAll experiments completed successfully.\")"
   ],
   "id": "ffad437f137dcb22",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T12:51:57.915047Z",
     "start_time": "2025-02-04T12:46:31.352156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define parameters\n",
    "config_directory = '/Users/macbook/CODE/PhantoMS/phantoms/models/denovo/configs'\n",
    "experiment_parent_directory = '/Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo'\n",
    "\n",
    "configuration_files = [\n",
    "    'config_denovo_local.yml',\n",
    "]\n",
    "tree_levels = [0, 1, 2, 3]\n",
    "\n",
    "wandb_project_name = 'cut_trees_denovo'\n",
    "\n",
    "# Authenticate with W&B\n",
    "print(\"Logging into Weights & Biases...\")\n",
    "wandb.login()\n",
    "\n",
    "# Run all experiments\n",
    "run_all_experiments(config_dir=config_directory,\n",
    "                    experiment_parent_dir=experiment_parent_directory,\n",
    "                    config_files=configuration_files,\n",
    "                    cut_tree_levels=tree_levels,\n",
    "                    wandb_project_name=wandb_project_name)"
   ],
   "id": "1f9b48425110e25a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging into Weights & Biases...\n",
      "\n",
      "Running Experiment: config_denovo_local_cut_tree_0_2025-02-04_13-46-31\n",
      "W&B Project: cut_trees_denovo\n",
      "Cut Tree Level: 0\n",
      "\n",
      "Starting training for /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_0_2025-02-04_13-46-31\n",
      "Using de novo task/model.\n",
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/CODE/PhantoMS/phantoms/utils/parser.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_state = torch.load(config['model'].get('decoder_pretrained_path'), map_location=\"cpu\")\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained decoder weights loaded into GATDeNovoTransformer.\n",
      "Loaded pretrained decoder into de novo model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250204_134632-5e48yl2m</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/5e48yl2m' target=\"_blank\">config_denovo_local_cut_tree_0_2025-02-04_13-46-31</a></strong> to <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/5e48yl2m' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/5e48yl2m</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | gat_layers          | ModuleList         | 6.2 M  | train\n",
      "1 | encoder_fc          | Linear             | 1.0 M  | train\n",
      "2 | transformer_decoder | TransformerDecoder | 67.2 M | train\n",
      "3 | pos_encoder         | PositionalEncoding | 0      | train\n",
      "4 | decoder_embed       | Embedding          | 303 K  | train\n",
      "5 | decoder_fc          | Linear             | 303 K  | train\n",
      "6 | criterion           | CrossEntropyLoss   | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "75.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "75.0 M    Total params\n",
      "300.181   Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Train dataset size: 82\n",
      "Val dataset size: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ce39adcddef4f6087ae1784c74da39d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "[13:46:41] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012�������6���.6�i��.6\u0013����������!��X����\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017q\u001C��6\u0013\u00176\u0016w��6\u0013�����6\u0013�����6\u0013�\u0016���6\u0013��\u0013�\u0016w���NCO�6�����\u001D\u001C��������i\u00036\u0013��6\u0013���\u0013��6\u0013��6\u0013���!\u0013����6���i������6��6�I\f\u0013���i�������6�COC��\n",
      "[13:46:41] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012�������6���.6�i��.6\u0013����������!��X����\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017q\u001C��6\u0013\u00176\u0016w��6\u0013�����6\u0013�����6\u0013�\u0016���6\u0013��\u0013�\u0016w���NCO�6�����\u001D\u001C��������i\u00036\u0013��6\u0013���\u0013��6\u0013��6\u0013���!\u0013����6���i������6��6�I\f\u0013���i�������6�COC��' for input: '������s\u001Cs\u001Cs\u001C������=\u0012�������6���.6�i��.6\u0013����������!��X����\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017q\u001C��6\u0013\u00176\u0016w��6\u0013�����6\u0013�����6\u0013�\u0016���6\u0013��\u0013�\u0016w���NCO�6�����\u001D\u001C��������i\u00036\u0013��6\u0013���\u0013��6\u0013��6\u0013���!\u0013����6���i������6��6�I\f\u0013���i�������6�COC��'\n",
      "[13:46:41] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs�������=\u0012������.��.X���.6\u0013����\u001D��������X�����\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017s\u0013\u0017s\u0013��6\u0016w��6��6\u0013��\u0013��F�\u0013��6\u0013����6\u0013��\u0013�\u0016w���NX�����a@]�i�6\u0013������i\u0003��\u0013��6\u0013���\u0013��6\u0013���ٗ�!6\u0013���i\u0019i\u0019�������6���iI\f\u0013���i�������NCO!6�\n",
      "[13:46:41] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs�������=\u0012������.��.X���.6\u0013����\u001D��������X�����\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017s\u0013\u0017s\u0013��6\u0016w��6��6\u0013��\u0013��F�\u0013��6\u0013����6\u0013��\u0013�\u0016w���NX�����a@]�i�6\u0013������i\u0003��\u0013��6\u0013���\u0013��6\u0013���ٗ�!6\u0013���i\u0019i\u0019�������6���iI\f\u0013���i�������NCO!6�' for input: '������s\u001Cs\u001Cs�������=\u0012������.��.X���.6\u0013����\u001D��������X�����\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017s\u0013\u0017s\u0013��6\u0016w��6��6\u0013��\u0013��F�\u0013��6\u0013����6\u0013��\u0013�\u0016w���NX�����a@]�i�6\u0013������i\u0003��\u0013��6\u0013���\u0013��6\u0013���ٗ�!6\u0013���i\u0019i\u0019�������6���iI\f\u0013���i�������NCO!6�'\n",
      "[13:46:49] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����a�F�a�a�\u0013\u0017a@]i������������a\u0013\u0017a�CCOC���6\u0013\u00176\u0016w�\u0013\u0017�F���6\u0013��\u0013��\u0013\u00176\u0013�\u0016��\u0013����\u0016w�����NX�����a@]�i�6\u0013�����i\u0003�\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013���!\u0013���iI�����\u0013���iI\f\u0013���i�������6\u0013���\n",
      "[13:46:49] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����a�F�a�a�\u0013\u0017a@]i������������a\u0013\u0017a�CCOC���6\u0013\u00176\u0016w�\u0013\u0017�F���6\u0013��\u0013��\u0013\u00176\u0013�\u0016��\u0013����\u0016w�����NX�����a@]�i�6\u0013�����i\u0003�\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013���!\u0013���iI�����\u0013���iI\f\u0013���i�������6\u0013���' for input: '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����a�F�a�a�\u0013\u0017a@]i������������a\u0013\u0017a�CCOC���6\u0013\u00176\u0016w�\u0013\u0017�F���6\u0013��\u0013��\u0013\u00176\u0013�\u0016��\u0013����\u0016w�����NX�����a@]�i�6\u0013�����i\u0003�\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013���!\u0013���iI�����\u0013���iI\f\u0013���i�������6\u0013���'\n",
      "[13:46:49] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012������.�.X���.�.6\u0013�����������\u0016��X���\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017s\u0013\u0017s\u0013��6\u0016w��6��6��F���6\u0013��\u0013��\u0013��\u0013��\u0013�\u0016w����NCO�6��a@]�i�6\u0013������i����\u0013\u001D6\u0013���\u0013��6\u0013���!\u0013���!\u0013���iI������6��6�I\f\u0013���i�������6�COC�6\n",
      "[13:46:49] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012������.�.X���.�.6\u0013�����������\u0016��X���\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017s\u0013\u0017s\u0013��6\u0016w��6��6��F���6\u0013��\u0013��\u0013��\u0013��\u0013�\u0016w����NCO�6��a@]�i�6\u0013������i����\u0013\u001D6\u0013���\u0013��6\u0013���!\u0013���!\u0013���iI������6��6�I\f\u0013���i�������6�COC�6' for input: '������s\u001Cs\u001Cs\u001C������=\u0012������.�.X���.�.6\u0013�����������\u0016��X���\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017s\u0013\u0017s\u0013��6\u0016w��6��6��F���6\u0013��\u0013��\u0013��\u0013��\u0013�\u0016w����NCO�6��a@]�i�6\u0013������i����\u0013\u001D6\u0013���\u0013��6\u0013���!\u0013���!\u0013���iI������6��6�I\f\u0013���i�������6�COC�6'\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6408d9ed4b5445938c728f0b66aec46b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9d51192a56b43118545017c0f9420b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:46:57] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:46:57] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[13:46:57] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:46:57] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[13:47:05] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:47:05] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[13:47:05] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:47:05] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56a56c4f40e946d19182969ad91a5c1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfa709f0ba044d9bbc5d49d5757804a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        Test metric                 DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_loss               8.015104293823242\n",
      "    test_num_valid_mols                 1.0\n",
      "    test_top_10_accuracy                0.0\n",
      "test_top_10_max_tanimoto_sim    0.03942422196269035\n",
      "   test_top_10_mces_dist               100.0\n",
      "    test_top_1_accuracy                 0.0\n",
      "test_top_1_max_tanimoto_sim     0.03942422196269035\n",
      "    test_top_1_mces_dist               100.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Model saved to /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_0_2025-02-04_13-46-31/checkpoints/final_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_num_valid_mols</td><td>▁</td></tr><tr><td>test_top_10_accuracy</td><td>▁</td></tr><tr><td>test_top_10_max_tanimoto_sim</td><td>▁</td></tr><tr><td>test_top_10_mces_dist</td><td>▁</td></tr><tr><td>test_top_1_accuracy</td><td>▁</td></tr><tr><td>test_top_1_max_tanimoto_sim</td><td>▁</td></tr><tr><td>test_top_1_mces_dist</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁▆█</td></tr><tr><td>val_loss</td><td>█▁</td></tr><tr><td>val_num_valid_mols</td><td>▁█</td></tr><tr><td>val_top_10_accuracy</td><td>▁▁</td></tr><tr><td>val_top_10_max_tanimoto_sim</td><td>▁█</td></tr><tr><td>val_top_10_mces_dist</td><td>▁▁</td></tr><tr><td>val_top_1_accuracy</td><td>▁▁</td></tr><tr><td>val_top_1_max_tanimoto_sim</td><td>▁█</td></tr><tr><td>val_top_1_mces_dist</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>test_loss</td><td>8.0151</td></tr><tr><td>test_num_valid_mols</td><td>1</td></tr><tr><td>test_top_10_accuracy</td><td>0</td></tr><tr><td>test_top_10_max_tanimoto_sim</td><td>0.03942</td></tr><tr><td>test_top_10_mces_dist</td><td>100</td></tr><tr><td>test_top_1_accuracy</td><td>0</td></tr><tr><td>test_top_1_max_tanimoto_sim</td><td>0.03942</td></tr><tr><td>test_top_1_mces_dist</td><td>100</td></tr><tr><td>trainer/global_step</td><td>4</td></tr><tr><td>val_loss</td><td>7.37718</td></tr><tr><td>val_num_valid_mols</td><td>1</td></tr><tr><td>val_top_10_accuracy</td><td>0</td></tr><tr><td>val_top_10_max_tanimoto_sim</td><td>0.03433</td></tr><tr><td>val_top_10_mces_dist</td><td>100</td></tr><tr><td>val_top_1_accuracy</td><td>0</td></tr><tr><td>val_top_1_max_tanimoto_sim</td><td>0.03433</td></tr><tr><td>val_top_1_mces_dist</td><td>100</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">config_denovo_local_cut_tree_0_2025-02-04_13-46-31</strong> at: <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/5e48yl2m' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/5e48yl2m</a><br> View project at: <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250204_134632-5e48yl2m/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_0_2025-02-04_13-46-31/configs/config_denovo_local.yml\n",
      "\n",
      "Extracting embeddings for /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_0_2025-02-04_13-46-31\n",
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n",
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 17\n",
      "Embeddings saved to /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_0_2025-02-04_13-46-31/embeddings\n",
      "\n",
      "Running Experiment: config_denovo_local_cut_tree_1_2025-02-04_13-47-47\n",
      "W&B Project: cut_trees_denovo\n",
      "Cut Tree Level: 1\n",
      "\n",
      "Starting training for /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_1_2025-02-04_13-47-47\n",
      "Using de novo task/model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/CODE/PhantoMS/phantoms/utils/parser.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_state = torch.load(config['model'].get('decoder_pretrained_path'), map_location=\"cpu\")\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n",
      "Pretrained decoder weights loaded into GATDeNovoTransformer.\n",
      "Loaded pretrained decoder into de novo model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250204_134749-rfwq1wwi</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/rfwq1wwi' target=\"_blank\">config_denovo_local_cut_tree_1_2025-02-04_13-47-47</a></strong> to <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/rfwq1wwi' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/rfwq1wwi</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | gat_layers          | ModuleList         | 6.2 M  | train\n",
      "1 | encoder_fc          | Linear             | 1.0 M  | train\n",
      "2 | transformer_decoder | TransformerDecoder | 67.2 M | train\n",
      "3 | pos_encoder         | PositionalEncoding | 0      | train\n",
      "4 | decoder_embed       | Embedding          | 303 K  | train\n",
      "5 | decoder_fc          | Linear             | 303 K  | train\n",
      "6 | criterion           | CrossEntropyLoss   | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "75.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "75.0 M    Total params\n",
      "300.181   Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Train dataset size: 82\n",
      "Val dataset size: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a18c46dd77d4433b567a18e0844f5b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "[13:48:00] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012�������6���.6�i��.6\u0013����������!��X����\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017s\u0013\u0017s\u0013��6\u0016w��6w�\u0013��\u0013��F���6\u0013�\u0016��6\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u0003��\u0013��6\u0013���\u0013��6\u0013���ٗ�!\u0013����6���iI�����6��6�I\f\u0013���i�������6\u0013���\n",
      "[13:48:00] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012�������6���.6�i��.6\u0013����������!��X����\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017s\u0013\u0017s\u0013��6\u0016w��6w�\u0013��\u0013��F���6\u0013�\u0016��6\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u0003��\u0013��6\u0013���\u0013��6\u0013���ٗ�!\u0013����6���iI�����6��6�I\f\u0013���i�������6\u0013���' for input: '������s\u001Cs\u001Cs\u001C������=\u0012�������6���.6�i��.6\u0013����������!��X����\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017s\u0013\u0017s\u0013��6\u0016w��6w�\u0013��\u0013��F���6\u0013�\u0016��6\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u0003��\u0013��6\u0013���\u0013��6\u0013���ٗ�!\u0013����6���iI�����6��6�I\f\u0013���i�������6\u0013���'\n",
      "[13:48:00] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012�������6���.6�i��.6\u0013����������!��X����\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017s\u0013\u0017s\u0013��6\u0016w��6w�\u0013��\u0013��F���6\u0013�\u0016��6\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u0003��\u0013��6\u0013���\u0013��6\u0013��6\u0013���!\u0013����6���������6���iI\f\u0013���i�������6\u0013���\n",
      "[13:48:00] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012�������6���.6�i��.6\u0013����������!��X����\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017s\u0013\u0017s\u0013��6\u0016w��6w�\u0013��\u0013��F���6\u0013�\u0016��6\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u0003��\u0013��6\u0013���\u0013��6\u0013��6\u0013���!\u0013����6���������6���iI\f\u0013���i�������6\u0013���' for input: '������s\u001Cs\u001Cs\u001C������=\u0012�������6���.6�i��.6\u0013����������!��X����\u0013\u0017a\u0013\u0017a�a\u0013\u0017a\u0013\u0017s\u0013\u0017s\u0013��6\u0016w��6w�\u0013��\u0013��F���6\u0013�\u0016��6\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u0003��\u0013��6\u0013���\u0013��6\u0013��6\u0013���!\u0013����6���������6���iI\f\u0013���i�������6\u0013���'\n",
      "[13:48:11] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����a�F�a�a�\u0013\u0017a@]i������������a\u0013\u0017a�CCOC���6\u0013\u00176\u0016w�\u0013\u00176\u0013��\u001C��\u0013�'s\u0013��6\u0013�\u0016��\u0013��\u0013�\u0016w����X�NX�������i�6\u0013�����i\u0003�\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013����6���iI������6������i��i�������6\u0013��6\n",
      "[13:48:11] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����a�F�a�a�\u0013\u0017a@]i������������a\u0013\u0017a�CCOC���6\u0013\u00176\u0016w�\u0013\u00176\u0013��\u001C��\u0013�'s\u0013��6\u0013�\u0016��\u0013��\u0013�\u0016w����X�NX�������i�6\u0013�����i\u0003�\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013����6���iI������6������i��i�������6\u0013��6' for input: '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����a�F�a�a�\u0013\u0017a@]i������������a\u0013\u0017a�CCOC���6\u0013\u00176\u0016w�\u0013\u00176\u0013��\u001C��\u0013�'s\u0013��6\u0013�\u0016��\u0013��\u0013�\u0016w����X�NX�������i�6\u0013�����i\u0003�\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013����6���iI������6������i��i�������6\u0013��6'\n",
      "[13:48:11] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.\u001D\u001C��a�\u0013���������������\u0013\u00176�X���a\u0013\u0017���\u0013\u0017a�OCCC�\u0013\u0017a�\u0013\u00176\u0013��\u0013��\u0013��\u0013��\u0013�\u0016���6\u0013�\u0016��������NX�����\u001D\u001C��������i\u00036\u0013��6\u0013��\u0013���\u0013��6\u0013���!6\u0013����6@@]�\u0013������6��6�I\f\u0013���i�6�I6�I\f\u0013����\n",
      "[13:48:11] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.\u001D\u001C��a�\u0013���������������\u0013\u00176�X���a\u0013\u0017���\u0013\u0017a�OCCC�\u0013\u0017a�\u0013\u00176\u0013��\u0013��\u0013��\u0013��\u0013�\u0016���6\u0013�\u0016��������NX�����\u001D\u001C��������i\u00036\u0013��6\u0013��\u0013���\u0013��6\u0013���!6\u0013����6@@]�\u0013������6��6�I\f\u0013���i�6�I6�I\f\u0013����' for input: '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.\u001D\u001C��a�\u0013���������������\u0013\u00176�X���a\u0013\u0017���\u0013\u0017a�OCCC�\u0013\u0017a�\u0013\u00176\u0013��\u0013��\u0013��\u0013��\u0013�\u0016���6\u0013�\u0016��������NX�����\u001D\u001C��������i\u00036\u0013��6\u0013��\u0013���\u0013��6\u0013���!6\u0013����6@@]�\u0013������6��6�I\f\u0013���i�6�I6�I\f\u0013����'\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90dea1f687ef438c9095b3916607964b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8110b07a400d467596a0621c795f2500"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:48:20] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:48:20] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[13:48:20] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:48:20] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[13:48:30] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:48:30] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[13:48:30] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:48:30] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "458104e4c85e4c6e926ff998b85b7639"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e60f83caa034397925008f432f55a48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        Test metric                 DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_loss               9.997653007507324\n",
      "    test_num_valid_mols                 1.0\n",
      "    test_top_10_accuracy                0.0\n",
      "test_top_10_max_tanimoto_sim    0.03942422196269035\n",
      "   test_top_10_mces_dist               100.0\n",
      "    test_top_1_accuracy                 0.0\n",
      "test_top_1_max_tanimoto_sim     0.03942422196269035\n",
      "    test_top_1_mces_dist               100.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Model saved to /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_1_2025-02-04_13-47-47/checkpoints/final_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_num_valid_mols</td><td>▁</td></tr><tr><td>test_top_10_accuracy</td><td>▁</td></tr><tr><td>test_top_10_max_tanimoto_sim</td><td>▁</td></tr><tr><td>test_top_10_mces_dist</td><td>▁</td></tr><tr><td>test_top_1_accuracy</td><td>▁</td></tr><tr><td>test_top_1_max_tanimoto_sim</td><td>▁</td></tr><tr><td>test_top_1_mces_dist</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁▆█</td></tr><tr><td>val_loss</td><td>█▁</td></tr><tr><td>val_num_valid_mols</td><td>▁█</td></tr><tr><td>val_top_10_accuracy</td><td>▁▁</td></tr><tr><td>val_top_10_max_tanimoto_sim</td><td>▁█</td></tr><tr><td>val_top_10_mces_dist</td><td>▁▁</td></tr><tr><td>val_top_1_accuracy</td><td>▁▁</td></tr><tr><td>val_top_1_max_tanimoto_sim</td><td>▁█</td></tr><tr><td>val_top_1_mces_dist</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>test_loss</td><td>9.99765</td></tr><tr><td>test_num_valid_mols</td><td>1</td></tr><tr><td>test_top_10_accuracy</td><td>0</td></tr><tr><td>test_top_10_max_tanimoto_sim</td><td>0.03942</td></tr><tr><td>test_top_10_mces_dist</td><td>100</td></tr><tr><td>test_top_1_accuracy</td><td>0</td></tr><tr><td>test_top_1_max_tanimoto_sim</td><td>0.03942</td></tr><tr><td>test_top_1_mces_dist</td><td>100</td></tr><tr><td>trainer/global_step</td><td>4</td></tr><tr><td>val_loss</td><td>9.60934</td></tr><tr><td>val_num_valid_mols</td><td>1</td></tr><tr><td>val_top_10_accuracy</td><td>0</td></tr><tr><td>val_top_10_max_tanimoto_sim</td><td>0.03433</td></tr><tr><td>val_top_10_mces_dist</td><td>100</td></tr><tr><td>val_top_1_accuracy</td><td>0</td></tr><tr><td>val_top_1_max_tanimoto_sim</td><td>0.03433</td></tr><tr><td>val_top_1_mces_dist</td><td>100</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">config_denovo_local_cut_tree_1_2025-02-04_13-47-47</strong> at: <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/rfwq1wwi' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/rfwq1wwi</a><br> View project at: <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250204_134749-rfwq1wwi/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_1_2025-02-04_13-47-47/configs/config_denovo_local.yml\n",
      "\n",
      "Extracting embeddings for /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_1_2025-02-04_13-47-47\n",
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n",
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 17\n",
      "Embeddings saved to /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_1_2025-02-04_13-47-47/embeddings\n",
      "\n",
      "Running Experiment: config_denovo_local_cut_tree_2_2025-02-04_13-49-13\n",
      "W&B Project: cut_trees_denovo\n",
      "Cut Tree Level: 2\n",
      "\n",
      "Starting training for /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_2_2025-02-04_13-49-13\n",
      "Using de novo task/model.\n",
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n",
      "Pretrained decoder weights loaded into GATDeNovoTransformer.\n",
      "Loaded pretrained decoder into de novo model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/CODE/PhantoMS/phantoms/utils/parser.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_state = torch.load(config['model'].get('decoder_pretrained_path'), map_location=\"cpu\")\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250204_134914-50wovgfb</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/50wovgfb' target=\"_blank\">config_denovo_local_cut_tree_2_2025-02-04_13-49-13</a></strong> to <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/50wovgfb' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/50wovgfb</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | gat_layers          | ModuleList         | 6.2 M  | train\n",
      "1 | encoder_fc          | Linear             | 1.0 M  | train\n",
      "2 | transformer_decoder | TransformerDecoder | 67.2 M | train\n",
      "3 | pos_encoder         | PositionalEncoding | 0      | train\n",
      "4 | decoder_embed       | Embedding          | 303 K  | train\n",
      "5 | decoder_fc          | Linear             | 303 K  | train\n",
      "6 | criterion           | CrossEntropyLoss   | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "75.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "75.0 M    Total params\n",
      "300.181   Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Train dataset size: 82\n",
      "Val dataset size: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8346a933539a4d72b27b0da0a70ad247"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "[13:49:24] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6\n",
      "[13:49:24] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6' for input: '������s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6'\n",
      "[13:49:24] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6\n",
      "[13:49:24] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6' for input: '������s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6'\n",
      "[13:49:32] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����\u001D���������������\u0013\u00176�X����\u0013\u0017���\u0013\u0017a�OCCC�\u0013\u0017a�F���6\u0013\u00176\u0013�\u0016��6\u0013\u0017a�\u0013��\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u00036\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013����6@@]�\u0013������6\u0013��6�I\f\u0013���i�������6\u0013��6\n",
      "[13:49:32] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����\u001D���������������\u0013\u00176�X����\u0013\u0017���\u0013\u0017a�OCCC�\u0013\u0017a�F���6\u0013\u00176\u0013�\u0016��6\u0013\u0017a�\u0013��\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u00036\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013����6@@]�\u0013������6\u0013��6�I\f\u0013���i�������6\u0013��6' for input: '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����\u001D���������������\u0013\u00176�X����\u0013\u0017���\u0013\u0017a�OCCC�\u0013\u0017a�F���6\u0013\u00176\u0013�\u0016��6\u0013\u0017a�\u0013��\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u00036\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013����6@@]�\u0013������6\u0013��6�I\f\u0013���i�������6\u0013��6'\n",
      "[13:49:32] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.��a�\u0013���������!\u0013\u0017a@]��\u0013\u00176�X���a\u0013\u0017a�CCOC���6��6\u0016w��\u0016w�\u0013��\u0013��\u0013��\u0013��\u0013�\u0016���6\u0013��\u0013�\u0016w����a\u0013�����a@]�i�6\u0013������i\u0003���\u0013\u001D6\u0013���\u0013��6\u0013���!\u0013���!6���iI�������6���iI\f\u0013���i�����6\u0013����\n",
      "[13:49:32] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.��a�\u0013���������!\u0013\u0017a@]��\u0013\u00176�X���a\u0013\u0017a�CCOC���6��6\u0016w��\u0016w�\u0013��\u0013��\u0013��\u0013��\u0013�\u0016���6\u0013��\u0013�\u0016w����a\u0013�����a@]�i�6\u0013������i\u0003���\u0013\u001D6\u0013���\u0013��6\u0013���!\u0013���!6���iI�������6���iI\f\u0013���i�����6\u0013����' for input: '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.��a�\u0013���������!\u0013\u0017a@]��\u0013\u00176�X���a\u0013\u0017a�CCOC���6��6\u0016w��\u0016w�\u0013��\u0013��\u0013��\u0013��\u0013�\u0016���6\u0013��\u0013�\u0016w����a\u0013�����a@]�i�6\u0013������i\u0003���\u0013\u001D6\u0013���\u0013��6\u0013���!\u0013���!6���iI�������6���iI\f\u0013���i�����6\u0013����'\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0a2d566bc08421aaec076c7bd5e6f0f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "185340c575784f54896f6d2f90dbf6ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:49:41] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:49:41] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[13:49:41] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:49:41] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[13:49:50] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:49:50] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[13:49:50] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:49:50] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f9f8833071948099513fa0bc273e376"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "586b34b8d3c44df9ae41f3517f187fb0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        Test metric                 DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_loss               9.578868865966797\n",
      "    test_num_valid_mols                 1.0\n",
      "    test_top_10_accuracy                0.0\n",
      "test_top_10_max_tanimoto_sim    0.03942422196269035\n",
      "   test_top_10_mces_dist               100.0\n",
      "    test_top_1_accuracy                 0.0\n",
      "test_top_1_max_tanimoto_sim     0.03942422196269035\n",
      "    test_top_1_mces_dist               100.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Model saved to /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_2_2025-02-04_13-49-13/checkpoints/final_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_num_valid_mols</td><td>▁</td></tr><tr><td>test_top_10_accuracy</td><td>▁</td></tr><tr><td>test_top_10_max_tanimoto_sim</td><td>▁</td></tr><tr><td>test_top_10_mces_dist</td><td>▁</td></tr><tr><td>test_top_1_accuracy</td><td>▁</td></tr><tr><td>test_top_1_max_tanimoto_sim</td><td>▁</td></tr><tr><td>test_top_1_mces_dist</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁▆█</td></tr><tr><td>val_loss</td><td>█▁</td></tr><tr><td>val_num_valid_mols</td><td>▁█</td></tr><tr><td>val_top_10_accuracy</td><td>▁▁</td></tr><tr><td>val_top_10_max_tanimoto_sim</td><td>▁█</td></tr><tr><td>val_top_10_mces_dist</td><td>▁▁</td></tr><tr><td>val_top_1_accuracy</td><td>▁▁</td></tr><tr><td>val_top_1_max_tanimoto_sim</td><td>▁█</td></tr><tr><td>val_top_1_mces_dist</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>test_loss</td><td>9.57887</td></tr><tr><td>test_num_valid_mols</td><td>1</td></tr><tr><td>test_top_10_accuracy</td><td>0</td></tr><tr><td>test_top_10_max_tanimoto_sim</td><td>0.03942</td></tr><tr><td>test_top_10_mces_dist</td><td>100</td></tr><tr><td>test_top_1_accuracy</td><td>0</td></tr><tr><td>test_top_1_max_tanimoto_sim</td><td>0.03942</td></tr><tr><td>test_top_1_mces_dist</td><td>100</td></tr><tr><td>trainer/global_step</td><td>4</td></tr><tr><td>val_loss</td><td>9.11422</td></tr><tr><td>val_num_valid_mols</td><td>1</td></tr><tr><td>val_top_10_accuracy</td><td>0</td></tr><tr><td>val_top_10_max_tanimoto_sim</td><td>0.03433</td></tr><tr><td>val_top_10_mces_dist</td><td>100</td></tr><tr><td>val_top_1_accuracy</td><td>0</td></tr><tr><td>val_top_1_max_tanimoto_sim</td><td>0.03433</td></tr><tr><td>val_top_1_mces_dist</td><td>100</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">config_denovo_local_cut_tree_2_2025-02-04_13-49-13</strong> at: <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/50wovgfb' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/50wovgfb</a><br> View project at: <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250204_134914-50wovgfb/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_2_2025-02-04_13-49-13/configs/config_denovo_local.yml\n",
      "\n",
      "Extracting embeddings for /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_2_2025-02-04_13-49-13\n",
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n",
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 17\n",
      "Embeddings saved to /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_2_2025-02-04_13-49-13/embeddings\n",
      "\n",
      "Running Experiment: config_denovo_local_cut_tree_3_2025-02-04_13-50-33\n",
      "W&B Project: cut_trees_denovo\n",
      "Cut Tree Level: 3\n",
      "\n",
      "Starting training for /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_3_2025-02-04_13-50-33\n",
      "Using de novo task/model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/CODE/PhantoMS/phantoms/utils/parser.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_state = torch.load(config['model'].get('decoder_pretrained_path'), map_location=\"cpu\")\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n",
      "Pretrained decoder weights loaded into GATDeNovoTransformer.\n",
      "Loaded pretrained decoder into de novo model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250204_135035-qmeykl45</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/qmeykl45' target=\"_blank\">config_denovo_local_cut_tree_3_2025-02-04_13-50-33</a></strong> to <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/qmeykl45' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/qmeykl45</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | gat_layers          | ModuleList         | 6.2 M  | train\n",
      "1 | encoder_fc          | Linear             | 1.0 M  | train\n",
      "2 | transformer_decoder | TransformerDecoder | 67.2 M | train\n",
      "3 | pos_encoder         | PositionalEncoding | 0      | train\n",
      "4 | decoder_embed       | Embedding          | 303 K  | train\n",
      "5 | decoder_fc          | Linear             | 303 K  | train\n",
      "6 | criterion           | CrossEntropyLoss   | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "75.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "75.0 M    Total params\n",
      "300.181   Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Train dataset size: 82\n",
      "Val dataset size: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0e2daacdc92447c89a9c38b780abc0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "[13:50:44] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6\n",
      "[13:50:44] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6' for input: '������s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6'\n",
      "[13:50:44] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6\n",
      "[13:50:44] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6' for input: '������s\u001Cs\u001Cs\u001C������=\u0012�������6��.X��.6\u0013�.6����������!�\u0013\u0017aX���\u0013\u0017a�a�a\u0013����\u0013\u0017s\u0013��6���\u0016w�\u0013�����6\u0013�'s\u0013\u00176\u0013�\u0016���6\u0013��\u0013�������NX�����a@]�i�6\u0013�����i��\u0013��6\u0013��\u0013���\u0013��6\u0013���!\u0013���!6@@]�\u0013�������6\u0013��6�I\f\u0013���i�������6\u0013��6'\n",
      "[13:50:53] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����\u001D���������������\u0013\u00176�X����\u0013\u0017���\u0013\u0017a�OCCC�\u0013\u0017a�F���6\u0013\u00176\u0013�\u0016��6\u0013\u0017a�\u0013��\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u00036\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013����6@@]�\u0013������6\u0013��6�I\f\u0013���i�������6\u0013��6\n",
      "[13:50:53] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����\u001D���������������\u0013\u00176�X����\u0013\u0017���\u0013\u0017a�OCCC�\u0013\u0017a�F���6\u0013\u00176\u0013�\u0016��6\u0013\u0017a�\u0013��\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u00036\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013����6@@]�\u0013������6\u0013��6�I\f\u0013���i�������6\u0013��6' for input: '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.6\u0013����\u001D���������������\u0013\u00176�X����\u0013\u0017���\u0013\u0017a�OCCC�\u0013\u0017a�F���6\u0013\u00176\u0013�\u0016��6\u0013\u0017a�\u0013��\u0013��\u0013�\u0016w�����NX�����a@]�i�6\u0013�����i\u00036\u0013��6\u0013��6\u0013��6\u0013��6\u0013���!\u0013����6@@]�\u0013������6\u0013��6�I\f\u0013���i�������6\u0013��6'\n",
      "[13:50:53] SMILES Parse Error: syntax error while parsing: s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.��a�\u0013���������!\u0013\u0017a@]��\u0013\u00176�X���a\u0013\u0017a�CCOC���6��6\u0016w��\u0016w�\u0013��\u0013��\u0013��\u0013��\u0013�\u0016���6\u0013��\u0013�\u0016w����a\u0013�����a@]�i�6\u0013������i\u0003���\u0013\u001D6\u0013���\u0013��6\u0013���!\u0013���!6���iI�������6���iI\f\u0013���i�����6\u0013����\n",
      "[13:50:53] SMILES Parse Error: Failed parsing SMILES '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.��a�\u0013���������!\u0013\u0017a@]��\u0013\u00176�X���a\u0013\u0017a�CCOC���6��6\u0016w��\u0016w�\u0013��\u0013��\u0013��\u0013��\u0013�\u0016���6\u0013��\u0013�\u0016w����a\u0013�����a@]�i�6\u0013������i\u0003���\u0013\u001D6\u0013���\u0013��6\u0013���!\u0013���!6���iI�������6���iI\f\u0013���i�����6\u0013����' for input: '������s\u001Cs\u001Cs\u001C������=\u0012������.��.X���.��a�\u0013���������!\u0013\u0017a@]��\u0013\u00176�X���a\u0013\u0017a�CCOC���6��6\u0016w��\u0016w�\u0013��\u0013��\u0013��\u0013��\u0013�\u0016���6\u0013��\u0013�\u0016w����a\u0013�����a@]�i�6\u0013������i\u0003���\u0013\u001D6\u0013���\u0013��6\u0013���!\u0013���!6���iI�������6���iI\f\u0013���i�����6\u0013����'\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7948dfa661e045729e461bf621438357"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84c192c4f005456394dd2d5fc0ca2951"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:51:03] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:51:03] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[13:51:03] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:51:03] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[13:51:11] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:51:11] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n",
      "[13:51:11] SMILES Parse Error: syntax error while parsing: ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))\n",
      "[13:51:11] SMILES Parse Error: Failed parsing SMILES '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))' for input: '))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4558bce5e214af0b1895cc8a6d326e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/phantoms_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4582735432454d5d9cbda2024665c186"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        Test metric                 DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_loss                9.61571979522705\n",
      "    test_num_valid_mols                 1.0\n",
      "    test_top_10_accuracy                0.0\n",
      "test_top_10_max_tanimoto_sim    0.03942422196269035\n",
      "   test_top_10_mces_dist               100.0\n",
      "    test_top_1_accuracy                 0.0\n",
      "test_top_1_max_tanimoto_sim     0.03942422196269035\n",
      "    test_top_1_mces_dist               100.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Model saved to /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_3_2025-02-04_13-50-33/checkpoints/final_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_num_valid_mols</td><td>▁</td></tr><tr><td>test_top_10_accuracy</td><td>▁</td></tr><tr><td>test_top_10_max_tanimoto_sim</td><td>▁</td></tr><tr><td>test_top_10_mces_dist</td><td>▁</td></tr><tr><td>test_top_1_accuracy</td><td>▁</td></tr><tr><td>test_top_1_max_tanimoto_sim</td><td>▁</td></tr><tr><td>test_top_1_mces_dist</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁▆█</td></tr><tr><td>val_loss</td><td>█▁</td></tr><tr><td>val_num_valid_mols</td><td>▁█</td></tr><tr><td>val_top_10_accuracy</td><td>▁▁</td></tr><tr><td>val_top_10_max_tanimoto_sim</td><td>▁█</td></tr><tr><td>val_top_10_mces_dist</td><td>▁▁</td></tr><tr><td>val_top_1_accuracy</td><td>▁▁</td></tr><tr><td>val_top_1_max_tanimoto_sim</td><td>▁█</td></tr><tr><td>val_top_1_mces_dist</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>test_loss</td><td>9.61572</td></tr><tr><td>test_num_valid_mols</td><td>1</td></tr><tr><td>test_top_10_accuracy</td><td>0</td></tr><tr><td>test_top_10_max_tanimoto_sim</td><td>0.03942</td></tr><tr><td>test_top_10_mces_dist</td><td>100</td></tr><tr><td>test_top_1_accuracy</td><td>0</td></tr><tr><td>test_top_1_max_tanimoto_sim</td><td>0.03942</td></tr><tr><td>test_top_1_mces_dist</td><td>100</td></tr><tr><td>trainer/global_step</td><td>4</td></tr><tr><td>val_loss</td><td>9.14651</td></tr><tr><td>val_num_valid_mols</td><td>1</td></tr><tr><td>val_top_10_accuracy</td><td>0</td></tr><tr><td>val_top_10_max_tanimoto_sim</td><td>0.03433</td></tr><tr><td>val_top_10_mces_dist</td><td>100</td></tr><tr><td>val_top_1_accuracy</td><td>0</td></tr><tr><td>val_top_1_max_tanimoto_sim</td><td>0.03433</td></tr><tr><td>val_top_1_mces_dist</td><td>100</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">config_denovo_local_cut_tree_3_2025-02-04_13-50-33</strong> at: <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/qmeykl45' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo/runs/qmeykl45</a><br> View project at: <a href='https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo' target=\"_blank\">https://wandb.ai/jozefov-iocb-prague/cut_trees_denovo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250204_135035-qmeykl45/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_3_2025-02-04_13-50-33/configs/config_denovo_local.yml\n",
      "\n",
      "Extracting embeddings for /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_3_2025-02-04_13-50-33\n",
      "Loaded tokenizer from /Users/macbook/CODE/PhantoMS/experiments_run/2025-02-03_17-46-47_tokenizer_test/smiles_tokenizer.json.\n",
      "Warning: Some identifiers in the split file are not found in the dataset. Taking intersection.\n",
      "Test dataset size: 17\n",
      "Embeddings saved to /Users/macbook/CODE/PhantoMS/experiments_run/cut_trees_denovo/config_denovo_local_cut_tree_3_2025-02-04_13-50-33/embeddings\n",
      "\n",
      "All experiments completed successfully.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "faee31607774ab53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "caa1cf6429be7b3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
